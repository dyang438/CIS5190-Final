{"cells":[{"cell_type":"markdown","metadata":{"id":"KXcv7eiotK7n"},"source":["# Imports and Mounting"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FZl_zZZZfFp0","executionInfo":{"status":"ok","timestamp":1715809192833,"user_tz":-480,"elapsed":18734,"user":{"displayName":"Matthew Kuo","userId":"14965226929628348940"}},"outputId":"658cd0db-46e5-435b-f331-083d8410653a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"02igopgYtQjz","executionInfo":{"status":"ok","timestamp":1715809215491,"user_tz":-480,"elapsed":22679,"user":{"displayName":"Matthew Kuo","userId":"14965226929628348940"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"252ded11-2eb7-4b28-8502-50f06701abb6"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.9/34.9 MB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["import pickle\n","import os\n","import random\n","import shutil\n","import pandas as pd\n","import numpy as np\n","import csv\n","\n","import torch\n","import torch.nn as nn\n","import torchvision.transforms as transforms\n","from torchvision.datasets import ImageFolder\n","from torch.utils.data import DataLoader, Subset\n","import torchvision.models as models\n","from torchvision.models import ResNet18_Weights\n","import torch.optim as optim\n","\n","from PIL import Image\n","from torch.utils.data import Dataset\n","\n","!pip install tqdm -q\n","from tqdm import tqdm\n","\n","!pip install rdkit -q\n","from rdkit import Chem\n","from rdkit.Chem.rdMolDescriptors import CalcMolFormula\n","\n","from collections import defaultdict\n","import re"]},{"cell_type":"markdown","metadata":{"id":"dyVUgrfbtMpI"},"source":["# Sampling the data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lqvAIau9yFsE"},"outputs":[],"source":["project_root = \"/content/drive/Shareddrives/CIS5190FinalProj\"\n","\n","handdrawn_root = \"/content/drive/Shareddrives/CIS5190FinalProj/DECIMER_HDM_Dataset_Images\"\n","computer_root = \"/content/drive/Shareddrives/CIS5190FinalProj/Img2Mol\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":59333,"status":"ok","timestamp":1715775173601,"user":{"displayName":"Matthew Kuo","userId":"14047253604617125631"},"user_tz":-480},"id":"8xe6Umwv1aoD","outputId":"c80159e9-c3bd-488f-eee5-3cdf09beeb94"},"outputs":[{"output_type":"stream","name":"stdout","text":["There are 5088 handdrawn images\n","There are 10880 computer generated images\n"]}],"source":["print(f\"There are {len(os.listdir(handdrawn_root))} handdrawn images\")\n","print(f\"There are {len(os.listdir(computer_root))} computer generated images\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9OspDQoJ0fZr"},"outputs":[],"source":["## Training : Validation : Testing = 7 : 2 : 1\n","# NUMBER_OF_TRAINING_IMGS = 7000\n","# NUMBER_OF_VAL_IMGS = NUMBER_OF_TRAINING_IMGS // 7 * 2\n","# NUMBER_OF_TESTING_IMGS = NUMBER_OF_TRAINING_IMGS // 7"]},{"cell_type":"markdown","metadata":{"id":"OntXA20swDlK"},"source":["## Creating image sets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HsJ8G8DMzZO9"},"outputs":[],"source":["def create_new_directory(directory):\n","    if os.path.exists(directory):\n","        shutil.rmtree(directory)\n","    os.makedirs(directory)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-kWQmdUBuBQS"},"outputs":[],"source":["## Randomly sample the images\n","def split_data(comp_gen_percentage=0.5):\n","    if comp_gen_percentage < 0.5:\n","        print(\"Computer generated percentage cannot be smaller than 0.5\")\n","        return\n","\n","    # Computer generated images\n","    num_comp_gen_imgs_train = int(comp_gen_percentage * NUMBER_OF_TRAINING_IMGS)\n","    num_comp_gen_imgs_val = int(comp_gen_percentage * NUMBER_OF_VAL_IMGS)\n","    num_comp_gen_imgs_test = int(comp_gen_percentage * NUMBER_OF_TESTING_IMGS)\n","\n","\n","    files = os.listdir(computer_root) # a list of names of computer-generated images\n","    random.shuffle(files)\n","\n","    comp_gen_filenames_train = files[:num_comp_gen_imgs_train]\n","    comp_gen_filenames_val = files[num_comp_gen_imgs_train: num_comp_gen_imgs_train+num_comp_gen_imgs_val]\n","    comp_gen_filenames_test = files[num_comp_gen_imgs_train+num_comp_gen_imgs_val:]\n","\n","    # Create the directories\n","    create_new_directory(train_root)\n","    create_new_directory(val_root)\n","    create_new_directory(test_root)\n","\n","    # Copy the images into the directories\n","    for filename in comp_gen_filenames_train:\n","        shutil.copy(os.path.join(computer_root, filename), train_root)\n","    for filename in comp_gen_filenames_val:\n","        shutil.copy(os.path.join(computer_root, filename), val_root)\n","    for filename in comp_gen_filenames_test:\n","        shutil.copy(os.path.join(computer_root, filename), test_root)\n","\n","\n","\n","    # Handdrawn images\n","    num_hand_imgs_train = int((1 - comp_gen_percentage) * NUMBER_OF_TRAINING_IMGS)\n","    num_hand_imgs_val = int((1 - comp_gen_percentage) * NUMBER_OF_VAL_IMGS)\n","    num_hand_imgs_test = int((1 - comp_gen_percentage) * NUMBER_OF_TESTING_IMGS)\n","\n","\n","    files = os.listdir(handdrawn_root)\n","    random.shuffle(files)\n","\n","    hand_filenames_train = files[:num_hand_imgs_train]\n","    hand_filenames_val = files[num_hand_imgs_train: num_hand_imgs_train+num_hand_imgs_val]\n","    hand_filenames_test = files[num_hand_imgs_train+num_hand_imgs_val:]\n","\n","    # Copy the images into the directories\n","    for filename in hand_filenames_train:\n","        shutil.copy(os.path.join(handdrawn_root, filename), train_root)\n","    for filename in hand_filenames_val:\n","        shutil.copy(os.path.join(handdrawn_root, filename), val_root)\n","    for filename in hand_filenames_test:\n","        shutil.copy(os.path.join(handdrawn_root, filename), test_root)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3vMtVnLOm825"},"outputs":[],"source":["## Only need to run this once\n","#split_data(1)"]},{"cell_type":"markdown","metadata":{"id":"gqCUIP3D2wPq"},"source":["## Loading the data into a dataloader"]},{"cell_type":"markdown","metadata":{"id":"QdL3Tfo82Gro"},"source":["### Get the labels"]},{"cell_type":"code","source":["periodic_table = [\"H\", \"He\", \"Li\", \"Be\", \"B\", \"C\", \"N\", \"O\", \"F\", \"Ne\",\n","                  \"Na\", \"Mg\", \"Al\", \"Si\", \"P\", \"S\", \"Cl\", \"Ar\", \"K\", \"Ca\",\n","                  \"Sc\", \"Ti\", \"V\", \"Cr\", \"Mn\", \"Fe\", \"Co\", \"Ni\", \"Cu\", \"Zn\",\n","                  \"Ga\", \"Ge\", \"As\", \"Se\", \"Br\", \"Kr\", \"Rb\", \"Sr\", \"Y\", \"Zr\",\n","                  \"Nb\", \"Mo\", \"Tc\", \"Ru\", \"Rh\", \"Pd\", \"Ag\", \"Cd\", \"In\", \"Sn\",\n","                  \"Sb\", \"Te\", \"I\", \"Xe\", \"Cs\", \"Ba\", \"La\", \"Ce\", \"Pr\", \"Nd\",\n","                  \"Pm\", \"Sm\", \"Eu\", \"Gd\", \"Tb\", \"Dy\", \"Ho\", \"Er\", \"Tm\", \"Yb\",\n","                  \"Lu\", \"Hf\", \"Ta\", \"W\", \"Re\", \"Os\", \"Ir\", \"Pt\", \"Au\", \"Hg\",\n","                  \"Tl\", \"Pb\", \"Bi\", \"Po\", \"At\", \"Rn\", \"Fr\", \"Ra\", \"Ac\", \"Th\",\n","                  \"Pa\", \"U\", \"Np\", \"Pu\", \"Am\", \"Cm\", \"Bk\", \"Cf\", \"Es\", \"Fm\",\n","                  \"Md\", \"No\", \"Lr\", \"Rf\", \"Db\", \"Sg\", \"Bh\", \"Hs\", \"Mt\", \"Ds\",\n","                  \"Rg\", \"Cn\", \"Nh\", \"Fl\", \"Mc\", \"Lv\", \"Ts\", \"Og\"]"],"metadata":{"id":"G-WCnp5z9Qbl"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m22vGLlKH538"},"outputs":[],"source":["def smiles_to_formula(smiles):\n","  mol = Chem.MolFromSmiles(smiles)\n","  formula = CalcMolFormula(mol)\n","  return formula\n","\n","def formula_to_atoms(formula):\n","  atoms = defaultdict(int)\n","  elements = re.findall(r'([A-Z][a-z]*)(\\d*)', formula)\n","  for element, count in elements:\n","    count = int(count) if count else 1\n","    atoms[element] += count\n","  return dict(atoms)\n","\n","\n","def smiles_to_atoms(smiles):\n","  formula = smiles_to_formula(smiles)\n","  return formula_to_atoms(formula)\n","\n","def atoms_to_array(atoms):\n","  # Initialize array with zeros for each element\n","  element_array = [0] * 118\n","  # Place the atom counts into the array based on the dictionary\n","  for element, count in atoms.items():\n","      if element in periodic_table:\n","          index = periodic_table.index(element)\n","          element_array[index] = count\n","  return element_array\n","\n","def atoms_to_binary_array(atoms):\n","    element_array = [0] * 118\n","    for element in atoms:\n","        if element in periodic_table:\n","            index = periodic_table.index(element)\n","            element_array[index] = 1\n","    return element_array"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2045,"status":"ok","timestamp":1715809419842,"user":{"displayName":"Matthew Kuo","userId":"14965226929628348940"},"user_tz":-480},"id":"LPivdIZ7vteR","outputId":"5536d5c2-3334-4380-aba2-d9ede619619e"},"outputs":[{"output_type":"stream","name":"stdout","text":["CDK_Depict_1_2 : [3, 0, 0, 0, 0, 6, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","CDK_Depict_1_4 : [6, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","CDK_Depict_1_5 : [45, 0, 0, 0, 0, 21, 0, 2, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","CDK_Depict_1_6 : [22, 0, 0, 0, 0, 15, 0, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","CDK_Depict_1_7 : [16, 0, 0, 0, 0, 8, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","CDK_Depict_1_2 : [1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","CDK_Depict_1_4 : [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","CDK_Depict_1_5 : [1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","CDK_Depict_1_6 : [1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","CDK_Depict_1_7 : [1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"]}],"source":["handdrawn_df = pd.read_csv(project_root + \"/DECIMER_HDM_Dataset_SMILES.tsv\", sep='\\t')\n","handdrawn_smiles_dict = handdrawn_df.set_index('IDs')['SMILES'].to_dict()\n","\n","# Process each SMILES to convert into atom arrays\n","handdrawn_atom_arrays = {key: atoms_to_array(smiles_to_atoms(value)) for key, value in handdrawn_smiles_dict.items()}\n","handdrawn_atom_binary_arrays = {key: atoms_to_binary_array(smiles_to_atoms(value)) for key, value in handdrawn_smiles_dict.items()}\n","\n","# To verify the transformation, print the first 5 elements of the transformed dictionary\n","for key in list(handdrawn_atom_arrays.keys())[:5]:\n","    print(key, \":\", handdrawn_atom_arrays[key])\n","for key in list(handdrawn_atom_binary_arrays.keys())[:5]:\n","    print(key, \":\", handdrawn_atom_binary_arrays[key])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gd2bgxLWIBaH"},"outputs":[],"source":["with open(\"/content/drive/Shareddrives/CIS5190FinalProj/Img2Mol_map.pkl\", 'rb') as f:\n","    comp_gen_df = pickle.load(f)\n","comp_gen_smiles_dict = comp_gen_df.set_index('Image')['SMILES'].to_dict()\n","comp_gen_atom_arrays = {key: atoms_to_array(smiles_to_atoms(value)) for key, value in comp_gen_smiles_dict.items()}\n","comp_gen_atom_binary_arrays = {key: atoms_to_binary_array(smiles_to_atoms(value)) for key, value in comp_gen_smiles_dict.items()}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"abiagvLIwHj3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715809437507,"user_tz":-480,"elapsed":25,"user":{"displayName":"Matthew Kuo","userId":"14965226929628348940"}},"outputId":"55d5a311-1e04-4435-ba39-1d929cc6c42b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Hand-drawn dataset first 5 atom arrays:\n","CDK_Depict_1_2 : [3, 0, 0, 0, 0, 6, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","CDK_Depict_1_4 : [6, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","CDK_Depict_1_5 : [45, 0, 0, 0, 0, 21, 0, 2, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","CDK_Depict_1_6 : [22, 0, 0, 0, 0, 15, 0, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","CDK_Depict_1_7 : [16, 0, 0, 0, 0, 8, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","\n","Computer-generated dataset first 5 atom arrays:\n","0.png : [20, 0, 0, 0, 0, 19, 2, 4, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","1.png : [17, 0, 0, 0, 0, 15, 3, 4, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","2.png : [17, 0, 0, 0, 0, 15, 6, 3, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","3.png : [16, 0, 0, 0, 0, 17, 2, 4, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","4.png : [21, 0, 0, 0, 0, 18, 3, 4, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","Hand-drawn dataset first 5 atom arrays:\n","CDK_Depict_1_2 : [1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","CDK_Depict_1_4 : [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","CDK_Depict_1_5 : [1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","CDK_Depict_1_6 : [1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","CDK_Depict_1_7 : [1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","\n","Computer-generated dataset first 5 atom arrays:\n","0.png : [1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","1.png : [1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","2.png : [1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","3.png : [1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","4.png : [1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"]}],"source":["# Verify transformation for both datasets by printing the first 5 elements\n","print(\"Hand-drawn dataset first 5 atom arrays:\")\n","for key in list(handdrawn_atom_arrays.keys())[:5]:\n","    print(key, \":\", handdrawn_atom_arrays[key])\n","\n","print(\"\\nComputer-generated dataset first 5 atom arrays:\")\n","for key in list(comp_gen_atom_arrays.keys())[:5]:\n","    print(key, \":\", comp_gen_atom_arrays[key])\n","\n","print(\"Hand-drawn dataset first 5 atom arrays:\")\n","for key in list(handdrawn_atom_binary_arrays.keys())[:5]:\n","    print(key, \":\", handdrawn_atom_binary_arrays[key])\n","\n","print(\"\\nComputer-generated dataset first 5 atom arrays:\")\n","for key in list(comp_gen_atom_binary_arrays.keys())[:5]:\n","    print(key, \":\", comp_gen_atom_binary_arrays[key])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dPsB6--J1zjO"},"outputs":[],"source":["## Combine the two dictionaries together\n","combined_mapping = handdrawn_atom_arrays.copy()\n","combined_binary_mapping = handdrawn_atom_binary_arrays.copy()\n","\n","for key, value in comp_gen_atom_arrays.items():\n","    # Remove .png from the key\n","    key = key.replace('.png', '')\n","    combined_mapping[key] = value\n","\n","for key, value in comp_gen_atom_binary_arrays.items():\n","    # Remove .png from the key\n","    key = key.replace('.png', '')\n","    combined_binary_mapping[key] = value"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"d4ImTfq42EGd"},"outputs":[],"source":["## Returns the label based on the filename of the image\n","\n","def get_binary_label(filename):\n","    return combined_binary_mapping.get(filename, None)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lpY7hlM82PPw"},"outputs":[],"source":["def validate_dataset(image_names, root_dir, label_dict):\n","    valid_image_names = []\n","    for img_name in image_names:\n","        img_path = os.path.join(root_dir, img_name)\n","        if os.path.isfile(img_path) and img_name.replace(\".png\", \"\") in label_dict:\n","            valid_image_names.append(img_name)\n","    return valid_image_names"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iq9iGf8n2FU8"},"outputs":[],"source":["class CustomDataset(Dataset):\n","    def __init__(self, root_dir, label_dict, transform=None):\n","        self.root_dir = root_dir\n","        self.transform = transform\n","        self.image_names = validate_dataset(os.listdir(root_dir), root_dir, label_dict)\n","        self.label_dict = label_dict\n","\n","    def __len__(self):\n","        return len(self.image_names)\n","\n","    def __getitem__(self, idx):\n","        img_name = self.image_names[idx]\n","        img_path = os.path.join(self.root_dir, img_name)\n","        image = Image.open(img_path).convert('RGB')\n","        label = self.label_dict[img_name.replace(\".png\", \"\")]\n","\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        label = torch.tensor(label, dtype=torch.float32)\n","        return image, label"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fh1RPiz3_YPg"},"outputs":[],"source":["def create_loaders(train_path, val_path, test_path):\n","    train_dataset = CustomDataset(root_dir=train_path, label_dict=combined_binary_mapping, transform=transform)\n","    val_dataset = CustomDataset(root_dir=val_path, label_dict=combined_binary_mapping, transform=transform)\n","    test_dataset = CustomDataset(root_dir=test_path, label_dict=combined_binary_mapping, transform=transform)\n","\n","    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)\n","    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True, num_workers=0)\n","    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True, num_workers=0)\n","\n","    return train_loader, val_loader, test_loader"]},{"cell_type":"markdown","source":["### Single point sanity check"],"metadata":{"id":"MRYi-hOI9pJH"}},{"cell_type":"code","source":["## Transformation\n","transform = transforms.Compose([\n","    transforms.Resize((256, 256)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])\n","\n","train_root = project_root + \"/Train5000_0.25\"\n","val_root = project_root + \"/Val5000_0.25\"\n","test_root = project_root + \"/Test5000_0.25\""],"metadata":{"id":"H6w6D39i98iO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_binary_dataset = CustomDataset(root_dir=train_root, label_dict=combined_binary_mapping, transform=transform)\n","val_binary_dataset = CustomDataset(root_dir=val_root, label_dict=combined_binary_mapping, transform=transform)\n","test_binary_dataset = CustomDataset(root_dir=test_root, label_dict=combined_binary_mapping, transform=transform)\n","\n","train_binary_loader = DataLoader(train_binary_dataset, batch_size=32, shuffle=True, num_workers=0)\n","val_binary_loader = DataLoader(val_binary_dataset, batch_size=32, shuffle=False, num_workers=0)\n","test_binary_loader = DataLoader(test_binary_dataset, batch_size=32, shuffle=False, num_workers=0)"],"metadata":{"id":"b3DFnNy5957q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["single_item_index = 0\n","single_item_binary_dataset = Subset(train_binary_dataset, [single_item_index])\n","single_item_binary_loader = DataLoader(single_item_binary_dataset, batch_size=1, shuffle=False)\n","for single_image, single_label in single_item_binary_loader:\n","    print(\"Image shape:\", single_image.shape)\n","    print(\"Label:\", single_label)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ESU7Wf6f9qwO","executionInfo":{"status":"ok","timestamp":1715771810543,"user_tz":-480,"elapsed":422,"user":{"displayName":"Matthew Kuo","userId":"14047253604617125631"}},"outputId":"7769ae40-3911-4ba6-e0a1-d6d81ebb5fb6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Image shape: torch.Size([1, 3, 256, 256])\n","Label: tensor([[1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n"]}]},{"cell_type":"markdown","metadata":{"id":"7q-Vof7a2tfh"},"source":["# Data Augmentation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NfGKlIxH3PQO"},"outputs":[],"source":["aug1 = transforms.Compose([\n","    transforms.RandomHorizontalFlip(),   # Random horizontal flip\n","    transforms.RandomRotation(degrees=15), # Random rotation by up to 15 degrees\n","    transforms.RandomAffine(degrees=15, translate=(0.1, 0.1), scale=(0.9, 1.1), shear=10)  # Random affine transformations\n","])\n","\n","# aug2 = transforms.Compose([\n","#     transforms.RandomResizedCrop(size=224),  # Random resized crop to 224x224\n","#     transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Color jitter\n","#     transforms.RandomAffine(degrees=15, translate=(0.1, 0.1), scale=(0.9, 1.1), shear=10)  # Random affine transformations\n","# ])\n","\n","# aug3 = transforms.Compose([\n","#     transforms.RandomHorizontalFlip(),   # Random horizontal flip\n","#     transforms.RandomRotation(degrees=15), # Random rotation by up to 15 degrees\n","#     transforms.RandomResizedCrop(size=224),  # Random resized crop to 224x224\n","#     transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Color jitter\n","#     transforms.RandomAffine(degrees=15, translate=(0.1, 0.1), scale=(0.9, 1.1), shear=10)  # Random affine transformations\n","# ])\n","\n","transform = transforms.Compose([\n","    transforms.Resize((256, 256)),\n","    aug1,\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])\n"]},{"cell_type":"markdown","metadata":{"id":"3_x8d1x054Jx"},"source":["# Model Pipeline\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1715809437509,"user":{"displayName":"Matthew Kuo","userId":"14965226929628348940"},"user_tz":-480},"id":"T7HGt-Av8r6l","outputId":"bfe15a04-6670-49e1-fa9f-f3adf074960a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]}],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f'Using device: {device}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jEVVHsy-OJ-H"},"outputs":[],"source":["def calculate_accuracy(preds, labels):\n","    # Ensure both predictions and labels are binary (0 or 1)\n","    preds = preds.round().int()\n","    labels = labels.int()\n","\n","    # Count matches where both prediction and label are 1\n","    correct_ones = (preds & labels).sum().item()\n","\n","    # Count total cases where either prediction or label is 1\n","    total_ones = ((preds == 1) | (labels == 1)).sum().item()\n","\n","    # Calculate accuracy based on matches and total relevant cases\n","    accuracy = correct_ones / total_ones if total_ones > 0 else 0.0\n","    return accuracy\n"]},{"cell_type":"code","source":["def calculate_batch_accuracy(outputs, labels):\n","    probs = torch.sigmoid(outputs)\n","    preds = (probs >= 0.5).float()\n","\n","    # Convert tensors to integer type for bitwise operations\n","    preds_int = preds.int()\n","    labels_int = labels.int()\n","\n","    # Correct matches where both prediction and label are 1\n","    correct_ones = (preds_int & labels_int).sum().item()\n","\n","    # Total relevant cases where either prediction or label is 1\n","    total_ones = ((preds_int == 1) | (labels_int == 1)).sum().item()\n","\n","    # Calculate accuracy based on matches and total relevant cases\n","    accuracy = correct_ones / total_ones if total_ones > 0 else 0.0\n","    return accuracy\n"],"metadata":{"id":"9g-VREKp-Ivv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_single_point(model, data_loader, criterion, optimizer, num_epochs=20):\n","    model.train()  # Set model to training mode\n","    for epoch in range(num_epochs):\n","        epoch_loss = 0.0\n","        correct_train = 0.0\n","        total_train = 0\n","\n","        for inputs, labels in data_loader:\n","            inputs, labels = inputs.to(device), labels.to(device)  # Move data to the correct device\n","\n","            optimizer.zero_grad()  # Zero the gradients\n","            outputs = model(inputs)  # Forward pass\n","            loss = criterion(outputs, labels)  # Compute loss\n","            loss.backward()  # Backpropagation\n","            optimizer.step()  # Update weights\n","\n","            epoch_loss += loss.item()\n","\n","            # Calculate batch accuracy\n","            batch_correct_train = calculate_batch_accuracy(outputs, labels)\n","            correct_train += batch_correct_train * labels.size(0)\n","            total_train += labels.size(0)\n","\n","        epoch_loss /= len(data_loader)\n","        epoch_accuracy = correct_train / total_train\n","\n","        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}')\n"],"metadata":{"id":"Dy2QW89p-J2l"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oUUBKQGB6dkm"},"outputs":[],"source":["def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=5, log_interval=10):\n","    train_losses = []\n","    train_accuracies = []\n","    val_losses = []\n","    val_accuracies = []\n","\n","    for epoch in range(num_epochs):\n","        model.train()\n","        running_loss = 0.0\n","        correct_train = 0.0\n","        total_train = 0\n","\n","        print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n","\n","        for batch_idx, (inputs, labels) in enumerate(train_loader):\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            optimizer.zero_grad()\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","            running_loss += loss.item()\n","\n","            batch_correct_train = calculate_batch_accuracy(outputs, labels)\n","            correct_train += batch_correct_train * labels.size(0)  # Accumulate correct predictions\n","            total_train += labels.size(0)  # Accumulate total predictions\n","\n","            if batch_idx % log_interval == 0:\n","                current_train_loss = running_loss / (batch_idx + 1)\n","                current_train_accuracy = correct_train / total_train\n","                print(f\"Train Batch [{batch_idx}/{len(train_loader)}], Loss: {current_train_loss:.4f}, Accuracy: {current_train_accuracy:.4f}\")\n","\n","        train_loss = running_loss / len(train_loader)\n","        train_accuracy = correct_train / total_train\n","\n","        # Validation phase\n","        model.eval()\n","        val_loss = 0.0\n","        correct_val = 0.0\n","        total_val = 0\n","\n","        with torch.no_grad():\n","            for batch_idx, (inputs, labels) in enumerate(val_loader):\n","                inputs, labels = inputs.to(device), labels.to(device)\n","                outputs = model(inputs)\n","                loss = criterion(outputs, labels)\n","                val_loss += loss.item()\n","\n","                batch_correct_val = calculate_batch_accuracy(outputs, labels)\n","                correct_val += batch_correct_val * labels.size(0)  # Accumulate correct predictions\n","                total_val += labels.size(0)  # Accumulate total predictions\n","\n","                if batch_idx % log_interval == 0:\n","                    current_val_loss = val_loss / (batch_idx + 1)\n","                    current_val_accuracy = correct_val / total_val\n","                    print(f\"Val Batch [{batch_idx}/{len(val_loader)}], Loss: {current_val_loss:.4f}, Accuracy: {current_val_accuracy:.4f}\")\n","\n","        val_loss = val_loss / len(val_loader)\n","        val_accuracy = correct_val / total_val\n","\n","        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')\n","\n","        # Append values for this epoch to the lists\n","        train_losses.append(train_loss)\n","        train_accuracies.append(train_accuracy)\n","        val_losses.append(val_loss)\n","        val_accuracies.append(val_accuracy)\n","\n","    return train_losses, train_accuracies, val_losses, val_accuracies\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p6RYjOVSOTXP"},"outputs":[],"source":["def test_model(model, test_loader, criterion):\n","    model.eval()\n","    test_loss = 0.0\n","    test_accuracy = 0.0\n","    total_batches = len(test_loader)\n","\n","    with torch.no_grad():\n","        for i, (inputs, labels) in enumerate(tqdm(test_loader, desc=\"Testing\")):\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            test_loss += loss.item()\n","\n","            # Calculate accuracy using the provided function\n","            batch_accuracy = calculate_batch_accuracy(outputs, labels)\n","            test_accuracy += batch_accuracy\n","\n","            # Debugging: Print predictions and targets\n","            if i % 50 == 0:\n","                # Apply sigmoid and threshold to show rounded predictions\n","                probs = torch.sigmoid(outputs)\n","                preds = (probs >= 0.5).float()\n","                print(f'Batch {i}/{total_batches}, Current Test Loss: {test_loss/(i+1):.4f}, Current Test Accuracy: {test_accuracy/(i+1):.4f}')\n","\n","    test_loss /= total_batches\n","    test_accuracy /= total_batches\n","\n","    print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}')\n","\n","    return test_loss, test_accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qAOBD-ZZFFSc"},"outputs":[],"source":["## Save things to a csv\n","def save_to_csv(csv_path, name, train_loss, train_acc, val_loss, val_acc, test_loss, test_acc):\n","    with open(csv_path, mode='a', newline='') as file:\n","        writer = csv.writer(file)\n","\n","        writer.writerow([name, train_loss, train_acc, val_loss, val_acc, test_loss, test_acc])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3rdfhkEuCQBh"},"outputs":[],"source":["NUM_EPOCHS = 10"]},{"cell_type":"markdown","source":["## Single Point Testing"],"metadata":{"id":"VpPhl5-m-cwS"}},{"cell_type":"code","source":["weights = ResNet18_Weights.DEFAULT\n","num_elements = 118\n","\n","resnet_binary = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n","for param in resnet_binary.parameters():\n","    param.requires_grad = True  # Unfreeze all layers\n","\n","num_binary_features = resnet_binary.fc.in_features\n","resnet_binary.fc = nn.Linear(num_binary_features, num_elements)\n","resnet_binary = resnet_binary.to(device)  # Move model to GPU"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KwbopzQd-hXP","executionInfo":{"status":"ok","timestamp":1715771973322,"user_tz":-480,"elapsed":1912,"user":{"displayName":"Matthew Kuo","userId":"14047253604617125631"}},"outputId":"7ac71bec-121d-4901-cdbd-f42c649b7b74"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n","100%|██████████| 44.7M/44.7M [00:00<00:00, 66.9MB/s]\n"]}]},{"cell_type":"code","source":["# Load Single Point ResNet model\n","resnet_single_binary = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n","for param in resnet_single_binary.parameters():\n","    param.requires_grad = True  # Unfreeze all layers\n","\n","num_single_binary_features = resnet_single_binary.fc.in_features\n","resnet_single_binary.fc = nn.Linear(num_single_binary_features, num_elements)\n","resnet_single_binary = resnet_single_binary.to(device)  # Move model to GPU\n","\n","criterion = nn.BCEWithLogitsLoss()\n","optimizer_single = torch.optim.SGD(resnet_single_binary.parameters(), lr=0.001, momentum=0.9)"],"metadata":{"id":"bMvIvoq1-mxB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_single_point(resnet_single_binary, single_item_binary_loader, criterion, optimizer_single, num_epochs=100)\n","test_model(resnet_single_binary, single_item_binary_loader, criterion)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yweIPPN7-nUB","executionInfo":{"status":"ok","timestamp":1715771979833,"user_tz":-480,"elapsed":5851,"user":{"displayName":"Matthew Kuo","userId":"14047253604617125631"}},"outputId":"73407a75-fbda-4da5-dc68-a8d6828b424d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/100], Loss: 0.7354, Accuracy: 0.0000\n","Epoch [2/100], Loss: 0.7342, Accuracy: 0.0000\n","Epoch [3/100], Loss: 0.7320, Accuracy: 0.0000\n","Epoch [4/100], Loss: 0.7288, Accuracy: 0.0000\n","Epoch [5/100], Loss: 0.7248, Accuracy: 0.0000\n","Epoch [6/100], Loss: 0.7201, Accuracy: 0.0000\n","Epoch [7/100], Loss: 0.7149, Accuracy: 0.0000\n","Epoch [8/100], Loss: 0.7091, Accuracy: 0.0000\n","Epoch [9/100], Loss: 0.7028, Accuracy: 0.0000\n","Epoch [10/100], Loss: 0.6961, Accuracy: 0.0000\n","Epoch [11/100], Loss: 0.6892, Accuracy: 0.0000\n","Epoch [12/100], Loss: 0.6820, Accuracy: 0.0189\n","Epoch [13/100], Loss: 0.6746, Accuracy: 0.0196\n","Epoch [14/100], Loss: 0.6670, Accuracy: 0.0200\n","Epoch [15/100], Loss: 0.6593, Accuracy: 0.0208\n","Epoch [16/100], Loss: 0.6515, Accuracy: 0.0222\n","Epoch [17/100], Loss: 0.6436, Accuracy: 0.0227\n","Epoch [18/100], Loss: 0.6357, Accuracy: 0.0238\n","Epoch [19/100], Loss: 0.6277, Accuracy: 0.0238\n","Epoch [20/100], Loss: 0.6198, Accuracy: 0.0238\n","Epoch [21/100], Loss: 0.6118, Accuracy: 0.0263\n","Epoch [22/100], Loss: 0.6039, Accuracy: 0.0270\n","Epoch [23/100], Loss: 0.5960, Accuracy: 0.0286\n","Epoch [24/100], Loss: 0.5882, Accuracy: 0.0294\n","Epoch [25/100], Loss: 0.5805, Accuracy: 0.0323\n","Epoch [26/100], Loss: 0.5728, Accuracy: 0.0333\n","Epoch [27/100], Loss: 0.5652, Accuracy: 0.0385\n","Epoch [28/100], Loss: 0.5577, Accuracy: 0.0385\n","Epoch [29/100], Loss: 0.5503, Accuracy: 0.0400\n","Epoch [30/100], Loss: 0.5429, Accuracy: 0.0417\n","Epoch [31/100], Loss: 0.5357, Accuracy: 0.0952\n","Epoch [32/100], Loss: 0.5286, Accuracy: 0.1000\n","Epoch [33/100], Loss: 0.5215, Accuracy: 0.1111\n","Epoch [34/100], Loss: 0.5146, Accuracy: 0.1333\n","Epoch [35/100], Loss: 0.5078, Accuracy: 0.1333\n","Epoch [36/100], Loss: 0.5011, Accuracy: 0.1333\n","Epoch [37/100], Loss: 0.4945, Accuracy: 0.2000\n","Epoch [38/100], Loss: 0.4880, Accuracy: 0.2308\n","Epoch [39/100], Loss: 0.4816, Accuracy: 0.2500\n","Epoch [40/100], Loss: 0.4753, Accuracy: 0.2727\n","Epoch [41/100], Loss: 0.4692, Accuracy: 0.3333\n","Epoch [42/100], Loss: 0.4631, Accuracy: 0.3333\n","Epoch [43/100], Loss: 0.4572, Accuracy: 0.3333\n","Epoch [44/100], Loss: 0.4513, Accuracy: 0.3750\n","Epoch [45/100], Loss: 0.4456, Accuracy: 0.3750\n","Epoch [46/100], Loss: 0.4400, Accuracy: 0.3750\n","Epoch [47/100], Loss: 0.4344, Accuracy: 0.3750\n","Epoch [48/100], Loss: 0.4290, Accuracy: 0.3750\n","Epoch [49/100], Loss: 0.4237, Accuracy: 0.3750\n","Epoch [50/100], Loss: 0.4184, Accuracy: 0.4286\n","Epoch [51/100], Loss: 0.4133, Accuracy: 0.4286\n","Epoch [52/100], Loss: 0.4082, Accuracy: 0.4286\n","Epoch [53/100], Loss: 0.4033, Accuracy: 0.5000\n","Epoch [54/100], Loss: 0.3984, Accuracy: 0.6000\n","Epoch [55/100], Loss: 0.3936, Accuracy: 0.7500\n","Epoch [56/100], Loss: 0.3889, Accuracy: 0.7500\n","Epoch [57/100], Loss: 0.3843, Accuracy: 0.7500\n","Epoch [58/100], Loss: 0.3798, Accuracy: 0.7500\n","Epoch [59/100], Loss: 0.3754, Accuracy: 0.7500\n","Epoch [60/100], Loss: 0.3710, Accuracy: 0.7500\n","Epoch [61/100], Loss: 0.3668, Accuracy: 0.7500\n","Epoch [62/100], Loss: 0.3626, Accuracy: 0.7500\n","Epoch [63/100], Loss: 0.3584, Accuracy: 0.7500\n","Epoch [64/100], Loss: 0.3544, Accuracy: 0.7500\n","Epoch [65/100], Loss: 0.3504, Accuracy: 1.0000\n","Epoch [66/100], Loss: 0.3465, Accuracy: 1.0000\n","Epoch [67/100], Loss: 0.3427, Accuracy: 1.0000\n","Epoch [68/100], Loss: 0.3389, Accuracy: 1.0000\n","Epoch [69/100], Loss: 0.3352, Accuracy: 1.0000\n","Epoch [70/100], Loss: 0.3315, Accuracy: 1.0000\n","Epoch [71/100], Loss: 0.3280, Accuracy: 1.0000\n","Epoch [72/100], Loss: 0.3245, Accuracy: 1.0000\n","Epoch [73/100], Loss: 0.3210, Accuracy: 1.0000\n","Epoch [74/100], Loss: 0.3176, Accuracy: 1.0000\n","Epoch [75/100], Loss: 0.3143, Accuracy: 1.0000\n","Epoch [76/100], Loss: 0.3110, Accuracy: 1.0000\n","Epoch [77/100], Loss: 0.3078, Accuracy: 1.0000\n","Epoch [78/100], Loss: 0.3046, Accuracy: 1.0000\n","Epoch [79/100], Loss: 0.3015, Accuracy: 1.0000\n","Epoch [80/100], Loss: 0.2984, Accuracy: 1.0000\n","Epoch [81/100], Loss: 0.2954, Accuracy: 1.0000\n","Epoch [82/100], Loss: 0.2925, Accuracy: 1.0000\n","Epoch [83/100], Loss: 0.2896, Accuracy: 1.0000\n","Epoch [84/100], Loss: 0.2867, Accuracy: 1.0000\n","Epoch [85/100], Loss: 0.2839, Accuracy: 1.0000\n","Epoch [86/100], Loss: 0.2811, Accuracy: 1.0000\n","Epoch [87/100], Loss: 0.2784, Accuracy: 1.0000\n","Epoch [88/100], Loss: 0.2757, Accuracy: 1.0000\n","Epoch [89/100], Loss: 0.2731, Accuracy: 1.0000\n","Epoch [90/100], Loss: 0.2705, Accuracy: 1.0000\n","Epoch [91/100], Loss: 0.2680, Accuracy: 1.0000\n","Epoch [92/100], Loss: 0.2655, Accuracy: 1.0000\n","Epoch [93/100], Loss: 0.2630, Accuracy: 1.0000\n","Epoch [94/100], Loss: 0.2606, Accuracy: 1.0000\n","Epoch [95/100], Loss: 0.2582, Accuracy: 1.0000\n","Epoch [96/100], Loss: 0.2558, Accuracy: 1.0000\n","Epoch [97/100], Loss: 0.2535, Accuracy: 1.0000\n","Epoch [98/100], Loss: 0.2512, Accuracy: 1.0000\n","Epoch [99/100], Loss: 0.2490, Accuracy: 1.0000\n","Epoch [100/100], Loss: 0.2468, Accuracy: 1.0000\n"]},{"output_type":"stream","name":"stderr","text":["Testing: 100%|██████████| 1/1 [00:00<00:00, 29.86it/s]"]},{"output_type":"stream","name":"stdout","text":["Batch 0/1, Current Test Loss: 0.2500, Current Test Accuracy: 1.0000\n","Predictions: [[1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n","  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n","  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n","  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n","  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n","Targets: [[1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n","  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n","  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n","  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n","  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n","Test Loss: 0.2500, Test Accuracy: 1.0000\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"execute_result","data":{"text/plain":["(0.2500499188899994, 1.0)"]},"metadata":{},"execution_count":38}]},{"cell_type":"markdown","source":["We can see that the model does \"memorize\" the single data point"],"metadata":{"id":"8aFz1kno-tMH"}},{"cell_type":"markdown","metadata":{"id":"Wyj2fF7k56IJ"},"source":["# VGG19"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nDTb4-Om22uP"},"outputs":[],"source":["def init_vgg19_hyperparameters():\n","    vgg19 = models.vgg19(pretrained=True)\n","\n","    # Freeze the pretrained weights\n","    for param in vgg19.parameters():\n","        param.requires_grad = False\n","\n","\n","    num_features = vgg19.classifier[6].in_features\n","    num_elements = 118\n","    vgg19.classifier[6] = nn.Linear(num_features, num_elements)\n","\n","    vgg19 = vgg19.to(device)\n","\n","    criterion = nn.BCEWithLogitsLoss()\n","    optimizer = torch.optim.SGD(vgg19.parameters(), lr=1e-4, momentum=0.9)\n","\n","    return vgg19, criterion, optimizer"]},{"cell_type":"markdown","metadata":{"id":"TYiFNwDM3rUK"},"source":["## 5000, 0.25"]},{"cell_type":"code","source":["train_loader, val_loader, test_loader = create_loaders(train_path=\"/content/drive/Shareddrives/CIS5190FinalProj/Train5000_0.25\",\n","                                                       val_path=\"/content/drive/Shareddrives/CIS5190FinalProj/Val5000_0.25\",\n","                                                       test_path=\"/content/drive/Shareddrives/CIS5190FinalProj/test_dataset\")\n","model, criterion, optimizer = init_vgg19_hyperparameters()\n","\n","## Train the model\n","vgg_train_losses_5000_25, vgg_train_accuracies_5000_25, vgg_val_losses_5000_25, vgg_val_accuracies_5000_25 = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=NUM_EPOCHS)\n","\n","## Test the model\n","vgg_test_loss_5000_25, vgg_test_accuracy_5000_25 = test_model(model, test_loader, criterion)\n","\n","## Save the model\n","torch.save(model.state_dict(), '/content/drive/Shareddrives/CIS5190FinalProj/vgg_5000_25.pth')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ImNpSrEJE-A7","outputId":"cf0147f8-e0b5-4fcb-8ac8-39bcd19b3a6d","executionInfo":{"status":"ok","timestamp":1715811803988,"user_tz":-480,"elapsed":1871636,"user":{"displayName":"Matthew Kuo","userId":"14965226929628348940"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n","100%|██████████| 548M/548M [00:06<00:00, 82.5MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/10]\n","Train Batch [0/110], Loss: 0.7167, Accuracy: 0.0305\n","Train Batch [10/110], Loss: 0.7071, Accuracy: 0.0295\n","Train Batch [20/110], Loss: 0.7034, Accuracy: 0.0300\n","Train Batch [30/110], Loss: 0.6989, Accuracy: 0.0306\n","Train Batch [40/110], Loss: 0.6933, Accuracy: 0.0318\n","Train Batch [50/110], Loss: 0.6874, Accuracy: 0.0335\n","Train Batch [60/110], Loss: 0.6817, Accuracy: 0.0350\n","Train Batch [70/110], Loss: 0.6761, Accuracy: 0.0364\n","Train Batch [80/110], Loss: 0.6705, Accuracy: 0.0377\n","Train Batch [90/110], Loss: 0.6650, Accuracy: 0.0395\n","Train Batch [100/110], Loss: 0.6595, Accuracy: 0.0412\n","Val Batch [0/32], Loss: 0.5884, Accuracy: 0.0918\n","Val Batch [10/32], Loss: 0.5882, Accuracy: 0.0930\n","Val Batch [20/32], Loss: 0.5884, Accuracy: 0.0934\n","Val Batch [30/32], Loss: 0.5883, Accuracy: 0.0925\n","Epoch [1/10], Train Loss: 0.6548, Train Accuracy: 0.0429, Val Loss: 0.5883, Val Accuracy: 0.0923\n","Epoch [2/10]\n","Train Batch [0/110], Loss: 0.5957, Accuracy: 0.0572\n","Train Batch [10/110], Loss: 0.5897, Accuracy: 0.0686\n","Train Batch [20/110], Loss: 0.5853, Accuracy: 0.0713\n","Train Batch [30/110], Loss: 0.5805, Accuracy: 0.0733\n","Train Batch [40/110], Loss: 0.5756, Accuracy: 0.0756\n","Train Batch [50/110], Loss: 0.5712, Accuracy: 0.0802\n","Train Batch [60/110], Loss: 0.5666, Accuracy: 0.0839\n","Train Batch [70/110], Loss: 0.5624, Accuracy: 0.0886\n","Train Batch [80/110], Loss: 0.5582, Accuracy: 0.0929\n","Train Batch [90/110], Loss: 0.5542, Accuracy: 0.0975\n","Train Batch [100/110], Loss: 0.5500, Accuracy: 0.1018\n","Val Batch [0/32], Loss: 0.4963, Accuracy: 0.4008\n","Val Batch [10/32], Loss: 0.4955, Accuracy: 0.4025\n","Val Batch [20/32], Loss: 0.4952, Accuracy: 0.3932\n","Val Batch [30/32], Loss: 0.4963, Accuracy: 0.3974\n","Epoch [2/10], Train Loss: 0.5464, Train Accuracy: 0.1058, Val Loss: 0.4965, Val Accuracy: 0.3978\n","Epoch [3/10]\n","Train Batch [0/110], Loss: 0.4998, Accuracy: 0.1518\n","Train Batch [10/110], Loss: 0.4986, Accuracy: 0.1570\n","Train Batch [20/110], Loss: 0.4953, Accuracy: 0.1727\n","Train Batch [30/110], Loss: 0.4923, Accuracy: 0.1795\n","Train Batch [40/110], Loss: 0.4879, Accuracy: 0.1864\n","Train Batch [50/110], Loss: 0.4844, Accuracy: 0.1955\n","Train Batch [60/110], Loss: 0.4808, Accuracy: 0.2049\n","Train Batch [70/110], Loss: 0.4773, Accuracy: 0.2135\n","Train Batch [80/110], Loss: 0.4737, Accuracy: 0.2208\n","Train Batch [90/110], Loss: 0.4704, Accuracy: 0.2294\n","Train Batch [100/110], Loss: 0.4668, Accuracy: 0.2377\n","Val Batch [0/32], Loss: 0.4255, Accuracy: 0.6190\n","Val Batch [10/32], Loss: 0.4289, Accuracy: 0.5712\n","Val Batch [20/32], Loss: 0.4282, Accuracy: 0.5790\n","Val Batch [30/32], Loss: 0.4280, Accuracy: 0.5876\n","Epoch [3/10], Train Loss: 0.4637, Train Accuracy: 0.2450, Val Loss: 0.4279, Val Accuracy: 0.5879\n","Epoch [4/10]\n","Train Batch [0/110], Loss: 0.4321, Accuracy: 0.3475\n","Train Batch [10/110], Loss: 0.4270, Accuracy: 0.3371\n","Train Batch [20/110], Loss: 0.4236, Accuracy: 0.3523\n","Train Batch [30/110], Loss: 0.4210, Accuracy: 0.3621\n","Train Batch [40/110], Loss: 0.4186, Accuracy: 0.3707\n","Train Batch [50/110], Loss: 0.4157, Accuracy: 0.3776\n","Train Batch [60/110], Loss: 0.4133, Accuracy: 0.3836\n","Train Batch [70/110], Loss: 0.4110, Accuracy: 0.3928\n","Train Batch [80/110], Loss: 0.4078, Accuracy: 0.4019\n","Train Batch [90/110], Loss: 0.4053, Accuracy: 0.4113\n","Train Batch [100/110], Loss: 0.4026, Accuracy: 0.4191\n","Val Batch [0/32], Loss: 0.3701, Accuracy: 0.6331\n","Val Batch [10/32], Loss: 0.3712, Accuracy: 0.6061\n","Val Batch [20/32], Loss: 0.3726, Accuracy: 0.6161\n","Val Batch [30/32], Loss: 0.3734, Accuracy: 0.6200\n","Epoch [4/10], Train Loss: 0.4008, Train Accuracy: 0.4256, Val Loss: 0.3735, Val Accuracy: 0.6201\n","Epoch [5/10]\n","Train Batch [0/110], Loss: 0.3680, Accuracy: 0.6154\n","Train Batch [10/110], Loss: 0.3755, Accuracy: 0.5002\n","Train Batch [20/110], Loss: 0.3714, Accuracy: 0.4967\n","Train Batch [30/110], Loss: 0.3684, Accuracy: 0.5025\n","Train Batch [40/110], Loss: 0.3649, Accuracy: 0.5080\n","Train Batch [50/110], Loss: 0.3628, Accuracy: 0.5142\n","Train Batch [60/110], Loss: 0.3609, Accuracy: 0.5206\n","Train Batch [70/110], Loss: 0.3593, Accuracy: 0.5224\n","Train Batch [80/110], Loss: 0.3577, Accuracy: 0.5241\n","Train Batch [90/110], Loss: 0.3557, Accuracy: 0.5310\n","Train Batch [100/110], Loss: 0.3536, Accuracy: 0.5363\n","Val Batch [0/32], Loss: 0.3375, Accuracy: 0.6108\n","Val Batch [10/32], Loss: 0.3339, Accuracy: 0.6314\n","Val Batch [20/32], Loss: 0.3335, Accuracy: 0.6261\n","Val Batch [30/32], Loss: 0.3327, Accuracy: 0.6214\n","Epoch [5/10], Train Loss: 0.3522, Train Accuracy: 0.5383, Val Loss: 0.3338, Val Accuracy: 0.6201\n","Epoch [6/10]\n","Train Batch [0/110], Loss: 0.3250, Accuracy: 0.5944\n","Train Batch [10/110], Loss: 0.3250, Accuracy: 0.5809\n","Train Batch [20/110], Loss: 0.3262, Accuracy: 0.5850\n","Train Batch [30/110], Loss: 0.3255, Accuracy: 0.5772\n","Train Batch [40/110], Loss: 0.3239, Accuracy: 0.5811\n","Train Batch [50/110], Loss: 0.3229, Accuracy: 0.5831\n","Train Batch [60/110], Loss: 0.3212, Accuracy: 0.5861\n","Train Batch [70/110], Loss: 0.3196, Accuracy: 0.5906\n","Train Batch [80/110], Loss: 0.3180, Accuracy: 0.5894\n","Train Batch [90/110], Loss: 0.3158, Accuracy: 0.5899\n","Train Batch [100/110], Loss: 0.3146, Accuracy: 0.5907\n","Val Batch [0/32], Loss: 0.2948, Accuracy: 0.7078\n","Val Batch [10/32], Loss: 0.2982, Accuracy: 0.6303\n","Val Batch [20/32], Loss: 0.2989, Accuracy: 0.6302\n","Val Batch [30/32], Loss: 0.2985, Accuracy: 0.6306\n","Epoch [6/10], Train Loss: 0.3133, Train Accuracy: 0.5921, Val Loss: 0.2987, Val Accuracy: 0.6314\n","Epoch [7/10]\n","Train Batch [0/110], Loss: 0.2980, Accuracy: 0.5952\n","Train Batch [10/110], Loss: 0.2936, Accuracy: 0.5994\n","Train Batch [20/110], Loss: 0.2941, Accuracy: 0.5942\n","Train Batch [30/110], Loss: 0.2940, Accuracy: 0.5977\n","Train Batch [40/110], Loss: 0.2927, Accuracy: 0.5997\n","Train Batch [50/110], Loss: 0.2907, Accuracy: 0.6038\n","Train Batch [60/110], Loss: 0.2884, Accuracy: 0.6015\n","Train Batch [70/110], Loss: 0.2877, Accuracy: 0.6032\n","Train Batch [80/110], Loss: 0.2866, Accuracy: 0.6057\n","Train Batch [90/110], Loss: 0.2852, Accuracy: 0.6058\n","Train Batch [100/110], Loss: 0.2842, Accuracy: 0.6084\n","Val Batch [0/32], Loss: 0.2758, Accuracy: 0.6667\n","Val Batch [10/32], Loss: 0.2729, Accuracy: 0.6468\n","Val Batch [20/32], Loss: 0.2723, Accuracy: 0.6478\n","Val Batch [30/32], Loss: 0.2716, Accuracy: 0.6312\n","Epoch [7/10], Train Loss: 0.2832, Train Accuracy: 0.6093, Val Loss: 0.2719, Val Accuracy: 0.6302\n","Epoch [8/10]\n","Train Batch [0/110], Loss: 0.2673, Accuracy: 0.5740\n","Train Batch [10/110], Loss: 0.2646, Accuracy: 0.6159\n","Train Batch [20/110], Loss: 0.2659, Accuracy: 0.6313\n","Train Batch [30/110], Loss: 0.2660, Accuracy: 0.6293\n","Train Batch [40/110], Loss: 0.2655, Accuracy: 0.6216\n","Train Batch [50/110], Loss: 0.2637, Accuracy: 0.6211\n","Train Batch [60/110], Loss: 0.2626, Accuracy: 0.6197\n","Train Batch [70/110], Loss: 0.2619, Accuracy: 0.6148\n","Train Batch [80/110], Loss: 0.2608, Accuracy: 0.6127\n","Train Batch [90/110], Loss: 0.2600, Accuracy: 0.6131\n","Train Batch [100/110], Loss: 0.2593, Accuracy: 0.6163\n","Val Batch [0/32], Loss: 0.2479, Accuracy: 0.6894\n","Val Batch [10/32], Loss: 0.2479, Accuracy: 0.6354\n","Val Batch [20/32], Loss: 0.2481, Accuracy: 0.6221\n","Val Batch [30/32], Loss: 0.2478, Accuracy: 0.6283\n","Epoch [8/10], Train Loss: 0.2587, Train Accuracy: 0.6180, Val Loss: 0.2478, Val Accuracy: 0.6277\n","Epoch [9/10]\n","Train Batch [0/110], Loss: 0.2480, Accuracy: 0.6467\n","Train Batch [10/110], Loss: 0.2496, Accuracy: 0.6242\n","Train Batch [20/110], Loss: 0.2469, Accuracy: 0.6212\n","Train Batch [30/110], Loss: 0.2441, Accuracy: 0.6276\n","Train Batch [40/110], Loss: 0.2434, Accuracy: 0.6268\n","Train Batch [50/110], Loss: 0.2429, Accuracy: 0.6235\n","Train Batch [60/110], Loss: 0.2416, Accuracy: 0.6222\n","Train Batch [70/110], Loss: 0.2405, Accuracy: 0.6255\n","Train Batch [80/110], Loss: 0.2400, Accuracy: 0.6245\n","Train Batch [90/110], Loss: 0.2390, Accuracy: 0.6250\n","Train Batch [100/110], Loss: 0.2381, Accuracy: 0.6255\n","Val Batch [0/32], Loss: 0.2300, Accuracy: 0.6562\n","Val Batch [10/32], Loss: 0.2316, Accuracy: 0.6280\n","Val Batch [20/32], Loss: 0.2315, Accuracy: 0.6255\n","Val Batch [30/32], Loss: 0.2304, Accuracy: 0.6290\n","Epoch [9/10], Train Loss: 0.2375, Train Accuracy: 0.6261, Val Loss: 0.2310, Val Accuracy: 0.6284\n","Epoch [10/10]\n","Train Batch [0/110], Loss: 0.2364, Accuracy: 0.6140\n","Train Batch [10/110], Loss: 0.2263, Accuracy: 0.6424\n","Train Batch [20/110], Loss: 0.2256, Accuracy: 0.6492\n","Train Batch [30/110], Loss: 0.2247, Accuracy: 0.6443\n","Train Batch [40/110], Loss: 0.2248, Accuracy: 0.6406\n","Train Batch [50/110], Loss: 0.2243, Accuracy: 0.6388\n","Train Batch [60/110], Loss: 0.2236, Accuracy: 0.6358\n","Train Batch [70/110], Loss: 0.2224, Accuracy: 0.6328\n","Train Batch [80/110], Loss: 0.2216, Accuracy: 0.6328\n","Train Batch [90/110], Loss: 0.2208, Accuracy: 0.6312\n","Train Batch [100/110], Loss: 0.2204, Accuracy: 0.6284\n","Val Batch [0/32], Loss: 0.2184, Accuracy: 0.6049\n","Val Batch [10/32], Loss: 0.2130, Accuracy: 0.6124\n","Val Batch [20/32], Loss: 0.2137, Accuracy: 0.6243\n","Val Batch [30/32], Loss: 0.2139, Accuracy: 0.6265\n","Epoch [10/10], Train Loss: 0.2198, Train Accuracy: 0.6273, Val Loss: 0.2141, Val Accuracy: 0.6276\n"]},{"output_type":"stream","name":"stderr","text":["Testing:   8%|▊         | 1/12 [00:14<02:41, 14.67s/it]"]},{"output_type":"stream","name":"stdout","text":["Batch 0/12, Current Test Loss: 0.2101, Current Test Accuracy: 0.6024\n"]},{"output_type":"stream","name":"stderr","text":["Testing: 100%|██████████| 12/12 [06:10<00:00, 30.85s/it]"]},{"output_type":"stream","name":"stdout","text":["Test Loss: 0.2112, Test Accuracy: 0.5945\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["## Save the results in a csv\n","save_to_csv(\"/content/drive/Shareddrives/CIS5190FinalProj/results2.csv\",\n","            \"VGG 5000 0.25\",\n","            vgg_train_losses_5000_25,\n","            vgg_train_accuracies_5000_25,\n","            vgg_val_losses_5000_25,\n","            vgg_val_accuracies_5000_25,\n","            vgg_test_loss_5000_25,\n","            vgg_test_accuracy_5000_25)"],"metadata":{"id":"hT556qIcfIA0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Q3Jh1O_m4L4h"},"source":["## 5000, 0.5"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xBvj59Dg56lJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715784010416,"user_tz":-480,"elapsed":5229641,"user":{"displayName":"Matthew Kuo","userId":"14047253604617125631"}},"outputId":"54d5cb2d-2c57-439e-b428-3d2a37a916e5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/10]\n","Train Batch [0/110], Loss: 0.7126, Accuracy: 0.0303\n","Train Batch [10/110], Loss: 0.7081, Accuracy: 0.0316\n","Train Batch [20/110], Loss: 0.7040, Accuracy: 0.0333\n","Train Batch [30/110], Loss: 0.6991, Accuracy: 0.0348\n","Train Batch [40/110], Loss: 0.6934, Accuracy: 0.0359\n","Train Batch [50/110], Loss: 0.6880, Accuracy: 0.0375\n","Train Batch [60/110], Loss: 0.6825, Accuracy: 0.0392\n","Train Batch [70/110], Loss: 0.6772, Accuracy: 0.0408\n","Train Batch [80/110], Loss: 0.6717, Accuracy: 0.0430\n","Train Batch [90/110], Loss: 0.6662, Accuracy: 0.0453\n","Train Batch [100/110], Loss: 0.6610, Accuracy: 0.0475\n","Val Batch [0/32], Loss: 0.5967, Accuracy: 0.1313\n","Val Batch [10/32], Loss: 0.5916, Accuracy: 0.1332\n","Val Batch [20/32], Loss: 0.5914, Accuracy: 0.1342\n","Val Batch [30/32], Loss: 0.5916, Accuracy: 0.1334\n","Epoch [1/10], Train Loss: 0.6562, Train Accuracy: 0.0496, Val Loss: 0.5917, Val Accuracy: 0.1336\n","Epoch [2/10]\n","Train Batch [0/110], Loss: 0.5936, Accuracy: 0.0774\n","Train Batch [10/110], Loss: 0.5933, Accuracy: 0.0792\n","Train Batch [20/110], Loss: 0.5894, Accuracy: 0.0832\n","Train Batch [30/110], Loss: 0.5840, Accuracy: 0.0866\n","Train Batch [40/110], Loss: 0.5799, Accuracy: 0.0909\n","Train Batch [50/110], Loss: 0.5755, Accuracy: 0.0956\n","Train Batch [60/110], Loss: 0.5711, Accuracy: 0.1005\n","Train Batch [70/110], Loss: 0.5669, Accuracy: 0.1054\n","Train Batch [80/110], Loss: 0.5626, Accuracy: 0.1107\n","Train Batch [90/110], Loss: 0.5585, Accuracy: 0.1165\n","Train Batch [100/110], Loss: 0.5543, Accuracy: 0.1229\n","Val Batch [0/32], Loss: 0.5084, Accuracy: 0.5128\n","Val Batch [10/32], Loss: 0.5026, Accuracy: 0.5203\n","Val Batch [20/32], Loss: 0.5028, Accuracy: 0.5169\n","Val Batch [30/32], Loss: 0.5020, Accuracy: 0.5165\n","Epoch [2/10], Train Loss: 0.5507, Train Accuracy: 0.1279, Val Loss: 0.5019, Val Accuracy: 0.5180\n","Epoch [3/10]\n","Train Batch [0/110], Loss: 0.5102, Accuracy: 0.1915\n","Train Batch [10/110], Loss: 0.5053, Accuracy: 0.1939\n","Train Batch [20/110], Loss: 0.5017, Accuracy: 0.2071\n","Train Batch [30/110], Loss: 0.4974, Accuracy: 0.2151\n","Train Batch [40/110], Loss: 0.4937, Accuracy: 0.2265\n","Train Batch [50/110], Loss: 0.4899, Accuracy: 0.2362\n","Train Batch [60/110], Loss: 0.4862, Accuracy: 0.2475\n","Train Batch [70/110], Loss: 0.4827, Accuracy: 0.2558\n","Train Batch [80/110], Loss: 0.4789, Accuracy: 0.2668\n","Train Batch [90/110], Loss: 0.4758, Accuracy: 0.2752\n","Train Batch [100/110], Loss: 0.4724, Accuracy: 0.2849\n","Val Batch [0/32], Loss: 0.4357, Accuracy: 0.6961\n","Val Batch [10/32], Loss: 0.4331, Accuracy: 0.6918\n","Val Batch [20/32], Loss: 0.4330, Accuracy: 0.6894\n","Val Batch [30/32], Loss: 0.4331, Accuracy: 0.6847\n","Epoch [3/10], Train Loss: 0.4696, Train Accuracy: 0.2927, Val Loss: 0.4327, Val Accuracy: 0.6852\n","Epoch [4/10]\n","Train Batch [0/110], Loss: 0.4351, Accuracy: 0.5000\n","Train Batch [10/110], Loss: 0.4356, Accuracy: 0.4019\n","Train Batch [20/110], Loss: 0.4310, Accuracy: 0.4112\n","Train Batch [30/110], Loss: 0.4282, Accuracy: 0.4225\n","Train Batch [40/110], Loss: 0.4245, Accuracy: 0.4340\n","Train Batch [50/110], Loss: 0.4217, Accuracy: 0.4439\n","Train Batch [60/110], Loss: 0.4190, Accuracy: 0.4528\n","Train Batch [70/110], Loss: 0.4162, Accuracy: 0.4594\n","Train Batch [80/110], Loss: 0.4136, Accuracy: 0.4700\n","Train Batch [90/110], Loss: 0.4112, Accuracy: 0.4762\n","Train Batch [100/110], Loss: 0.4087, Accuracy: 0.4831\n","Val Batch [0/32], Loss: 0.3751, Accuracy: 0.6630\n","Val Batch [10/32], Loss: 0.3799, Accuracy: 0.6974\n","Val Batch [20/32], Loss: 0.3799, Accuracy: 0.6986\n","Val Batch [30/32], Loss: 0.3804, Accuracy: 0.7018\n","Epoch [4/10], Train Loss: 0.4069, Train Accuracy: 0.4889, Val Loss: 0.3803, Val Accuracy: 0.7015\n","Epoch [5/10]\n","Train Batch [0/110], Loss: 0.3845, Accuracy: 0.5885\n","Train Batch [10/110], Loss: 0.3803, Accuracy: 0.5745\n","Train Batch [20/110], Loss: 0.3769, Accuracy: 0.5793\n","Train Batch [30/110], Loss: 0.3738, Accuracy: 0.5865\n","Train Batch [40/110], Loss: 0.3719, Accuracy: 0.5908\n","Train Batch [50/110], Loss: 0.3694, Accuracy: 0.5960\n","Train Batch [60/110], Loss: 0.3677, Accuracy: 0.5975\n","Train Batch [70/110], Loss: 0.3662, Accuracy: 0.5984\n","Train Batch [80/110], Loss: 0.3641, Accuracy: 0.6029\n","Train Batch [90/110], Loss: 0.3622, Accuracy: 0.6079\n","Train Batch [100/110], Loss: 0.3602, Accuracy: 0.6127\n","Val Batch [0/32], Loss: 0.3393, Accuracy: 0.7049\n","Val Batch [10/32], Loss: 0.3376, Accuracy: 0.7218\n","Val Batch [20/32], Loss: 0.3387, Accuracy: 0.7067\n","Val Batch [30/32], Loss: 0.3385, Accuracy: 0.7064\n","Epoch [5/10], Train Loss: 0.3583, Train Accuracy: 0.6168, Val Loss: 0.3384, Val Accuracy: 0.7064\n","Epoch [6/10]\n","Train Batch [0/110], Loss: 0.3410, Accuracy: 0.6705\n","Train Batch [10/110], Loss: 0.3355, Accuracy: 0.6640\n","Train Batch [20/110], Loss: 0.3344, Accuracy: 0.6592\n","Train Batch [30/110], Loss: 0.3314, Accuracy: 0.6659\n","Train Batch [40/110], Loss: 0.3293, Accuracy: 0.6622\n","Train Batch [50/110], Loss: 0.3276, Accuracy: 0.6634\n","Train Batch [60/110], Loss: 0.3262, Accuracy: 0.6673\n","Train Batch [70/110], Loss: 0.3245, Accuracy: 0.6690\n","Train Batch [80/110], Loss: 0.3228, Accuracy: 0.6703\n","Train Batch [90/110], Loss: 0.3213, Accuracy: 0.6702\n","Train Batch [100/110], Loss: 0.3199, Accuracy: 0.6715\n","Val Batch [0/32], Loss: 0.3002, Accuracy: 0.6936\n","Val Batch [10/32], Loss: 0.3047, Accuracy: 0.7085\n","Val Batch [20/32], Loss: 0.3059, Accuracy: 0.7035\n","Val Batch [30/32], Loss: 0.3054, Accuracy: 0.7005\n","Epoch [6/10], Train Loss: 0.3184, Train Accuracy: 0.6719, Val Loss: 0.3051, Val Accuracy: 0.7007\n","Epoch [7/10]\n","Train Batch [0/110], Loss: 0.3018, Accuracy: 0.6629\n","Train Batch [10/110], Loss: 0.3034, Accuracy: 0.6573\n","Train Batch [20/110], Loss: 0.2996, Accuracy: 0.6697\n","Train Batch [30/110], Loss: 0.2980, Accuracy: 0.6823\n","Train Batch [40/110], Loss: 0.2974, Accuracy: 0.6864\n","Train Batch [50/110], Loss: 0.2956, Accuracy: 0.6859\n","Train Batch [60/110], Loss: 0.2939, Accuracy: 0.6876\n","Train Batch [70/110], Loss: 0.2929, Accuracy: 0.6873\n","Train Batch [80/110], Loss: 0.2917, Accuracy: 0.6905\n","Train Batch [90/110], Loss: 0.2903, Accuracy: 0.6898\n","Train Batch [100/110], Loss: 0.2887, Accuracy: 0.6921\n","Val Batch [0/32], Loss: 0.2853, Accuracy: 0.6914\n","Val Batch [10/32], Loss: 0.2776, Accuracy: 0.7055\n","Val Batch [20/32], Loss: 0.2772, Accuracy: 0.7108\n","Val Batch [30/32], Loss: 0.2765, Accuracy: 0.7056\n","Epoch [7/10], Train Loss: 0.2876, Train Accuracy: 0.6925, Val Loss: 0.2761, Val Accuracy: 0.7057\n","Epoch [8/10]\n","Train Batch [0/110], Loss: 0.2734, Accuracy: 0.6821\n","Train Batch [10/110], Loss: 0.2731, Accuracy: 0.6882\n","Train Batch [20/110], Loss: 0.2718, Accuracy: 0.6871\n","Train Batch [30/110], Loss: 0.2724, Accuracy: 0.6857\n","Train Batch [40/110], Loss: 0.2716, Accuracy: 0.6872\n","Train Batch [50/110], Loss: 0.2701, Accuracy: 0.6916\n","Train Batch [60/110], Loss: 0.2692, Accuracy: 0.6884\n","Train Batch [70/110], Loss: 0.2678, Accuracy: 0.6915\n","Train Batch [80/110], Loss: 0.2668, Accuracy: 0.6949\n","Train Batch [90/110], Loss: 0.2655, Accuracy: 0.6970\n","Train Batch [100/110], Loss: 0.2642, Accuracy: 0.6989\n","Val Batch [0/32], Loss: 0.2561, Accuracy: 0.6860\n","Val Batch [10/32], Loss: 0.2519, Accuracy: 0.7149\n","Val Batch [20/32], Loss: 0.2528, Accuracy: 0.7128\n","Val Batch [30/32], Loss: 0.2530, Accuracy: 0.7045\n","Epoch [8/10], Train Loss: 0.2631, Train Accuracy: 0.6984, Val Loss: 0.2535, Val Accuracy: 0.7051\n","Epoch [9/10]\n","Train Batch [0/110], Loss: 0.2588, Accuracy: 0.7805\n","Train Batch [10/110], Loss: 0.2490, Accuracy: 0.6954\n","Train Batch [20/110], Loss: 0.2473, Accuracy: 0.7042\n","Train Batch [30/110], Loss: 0.2468, Accuracy: 0.7012\n","Train Batch [40/110], Loss: 0.2473, Accuracy: 0.6989\n","Train Batch [50/110], Loss: 0.2462, Accuracy: 0.6977\n","Train Batch [60/110], Loss: 0.2460, Accuracy: 0.7025\n","Train Batch [70/110], Loss: 0.2449, Accuracy: 0.7010\n","Train Batch [80/110], Loss: 0.2438, Accuracy: 0.7014\n","Train Batch [90/110], Loss: 0.2428, Accuracy: 0.7000\n","Train Batch [100/110], Loss: 0.2420, Accuracy: 0.7020\n","Val Batch [0/32], Loss: 0.2380, Accuracy: 0.7500\n","Val Batch [10/32], Loss: 0.2365, Accuracy: 0.7124\n","Val Batch [20/32], Loss: 0.2335, Accuracy: 0.7123\n","Val Batch [30/32], Loss: 0.2333, Accuracy: 0.7117\n","Epoch [9/10], Train Loss: 0.2413, Train Accuracy: 0.7029, Val Loss: 0.2336, Val Accuracy: 0.7095\n","Epoch [10/10]\n","Train Batch [0/110], Loss: 0.2200, Accuracy: 0.7151\n","Train Batch [10/110], Loss: 0.2293, Accuracy: 0.7194\n","Train Batch [20/110], Loss: 0.2290, Accuracy: 0.7224\n","Train Batch [30/110], Loss: 0.2281, Accuracy: 0.7162\n","Train Batch [40/110], Loss: 0.2267, Accuracy: 0.7220\n","Train Batch [50/110], Loss: 0.2261, Accuracy: 0.7181\n","Train Batch [60/110], Loss: 0.2256, Accuracy: 0.7127\n","Train Batch [70/110], Loss: 0.2242, Accuracy: 0.7136\n","Train Batch [80/110], Loss: 0.2240, Accuracy: 0.7117\n","Train Batch [90/110], Loss: 0.2231, Accuracy: 0.7090\n","Train Batch [100/110], Loss: 0.2232, Accuracy: 0.7079\n","Val Batch [0/32], Loss: 0.2191, Accuracy: 0.7314\n","Val Batch [10/32], Loss: 0.2175, Accuracy: 0.7230\n","Val Batch [20/32], Loss: 0.2189, Accuracy: 0.7062\n","Val Batch [30/32], Loss: 0.2178, Accuracy: 0.7056\n","Epoch [10/10], Train Loss: 0.2227, Train Accuracy: 0.7074, Val Loss: 0.2179, Val Accuracy: 0.7053\n"]},{"output_type":"stream","name":"stderr","text":["Testing:   6%|▋         | 1/16 [00:34<08:39, 34.61s/it]"]},{"output_type":"stream","name":"stdout","text":["Batch 0/16, Current Test Loss: 0.2295, Current Test Accuracy: 0.7365\n"]},{"output_type":"stream","name":"stderr","text":["Testing: 100%|██████████| 16/16 [07:36<00:00, 28.51s/it]"]},{"output_type":"stream","name":"stdout","text":["Test Loss: 0.2170, Test Accuracy: 0.7191\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["train_loader, val_loader, test_loader = create_loaders(train_path=\"/content/drive/Shareddrives/CIS5190FinalProj/Train5000_0.5\",\n","                                                       val_path=\"/content/drive/Shareddrives/CIS5190FinalProj/Val5000_0.5\",\n","                                                       test_path=\"/content/drive/Shareddrives/CIS5190FinalProj/test_dataset\")\n","model, criterion, optimizer = init_vgg19_hyperparameters()\n","\n","## Train the model\n","vgg_train_losses_5000_50, vgg_train_accuracies_5000_50, vgg_val_losses_5000_50, vgg_val_accuracies_5000_50 = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=NUM_EPOCHS)\n","\n","## Test the model\n","vgg_test_loss_5000_50, vgg_test_accuracy_5000_50 = test_model(model, test_loader, criterion)\n","\n","## Save the model\n","torch.save(model.state_dict(), '/content/drive/Shareddrives/CIS5190FinalProj/vgg_5000_50.pth')"]},{"cell_type":"code","source":["save_to_csv(\"/content/drive/Shareddrives/CIS5190FinalProj/results2.csv\",\n","            \"VGG 5000 0.50\",\n","            vgg_train_losses_5000_50,\n","            vgg_train_accuracies_5000_50,\n","            vgg_val_losses_5000_50,\n","            vgg_val_accuracies_5000_50,\n","            vgg_test_loss_5000_50,\n","            vgg_test_accuracy_5000_50)"],"metadata":{"id":"b1PzmqRXq5fx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Jyos2S9b4Zcv"},"source":["## 5000, 0.75"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q3f4shky47u9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715786425435,"user_tz":-480,"elapsed":2140701,"user":{"displayName":"Matthew Kuo","userId":"14047253604617125631"}},"outputId":"041ed384-0bf8-4e43-812f-8d75e49f10f6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/10]\n","Train Batch [0/110], Loss: 0.7146, Accuracy: 0.0393\n","Train Batch [10/110], Loss: 0.7097, Accuracy: 0.0411\n","Train Batch [20/110], Loss: 0.7062, Accuracy: 0.0411\n","Train Batch [30/110], Loss: 0.7018, Accuracy: 0.0431\n","Train Batch [40/110], Loss: 0.6963, Accuracy: 0.0443\n","Train Batch [50/110], Loss: 0.6909, Accuracy: 0.0459\n","Train Batch [60/110], Loss: 0.6856, Accuracy: 0.0475\n","Train Batch [70/110], Loss: 0.6805, Accuracy: 0.0493\n","Train Batch [80/110], Loss: 0.6752, Accuracy: 0.0512\n","Train Batch [90/110], Loss: 0.6699, Accuracy: 0.0535\n","Train Batch [100/110], Loss: 0.6645, Accuracy: 0.0562\n","Val Batch [0/32], Loss: 0.5975, Accuracy: 0.1417\n","Val Batch [10/32], Loss: 0.5960, Accuracy: 0.1375\n","Val Batch [20/32], Loss: 0.5960, Accuracy: 0.1334\n","Val Batch [30/32], Loss: 0.5962, Accuracy: 0.1313\n","Epoch [1/10], Train Loss: 0.6599, Train Accuracy: 0.0583, Val Loss: 0.5960, Val Accuracy: 0.1313\n","Epoch [2/10]\n","Train Batch [0/110], Loss: 0.6018, Accuracy: 0.0979\n","Train Batch [10/110], Loss: 0.5964, Accuracy: 0.0918\n","Train Batch [20/110], Loss: 0.5928, Accuracy: 0.0951\n","Train Batch [30/110], Loss: 0.5891, Accuracy: 0.0996\n","Train Batch [40/110], Loss: 0.5843, Accuracy: 0.1039\n","Train Batch [50/110], Loss: 0.5800, Accuracy: 0.1086\n","Train Batch [60/110], Loss: 0.5753, Accuracy: 0.1141\n","Train Batch [70/110], Loss: 0.5712, Accuracy: 0.1200\n","Train Batch [80/110], Loss: 0.5668, Accuracy: 0.1252\n","Train Batch [90/110], Loss: 0.5627, Accuracy: 0.1307\n","Train Batch [100/110], Loss: 0.5588, Accuracy: 0.1371\n","Val Batch [0/32], Loss: 0.5077, Accuracy: 0.6435\n","Val Batch [10/32], Loss: 0.5080, Accuracy: 0.5687\n","Val Batch [20/32], Loss: 0.5074, Accuracy: 0.5620\n","Val Batch [30/32], Loss: 0.5070, Accuracy: 0.5740\n","Epoch [2/10], Train Loss: 0.5551, Train Accuracy: 0.1432, Val Loss: 0.5072, Val Accuracy: 0.5740\n","Epoch [3/10]\n","Train Batch [0/110], Loss: 0.5128, Accuracy: 0.2426\n","Train Batch [10/110], Loss: 0.5065, Accuracy: 0.2311\n","Train Batch [20/110], Loss: 0.5026, Accuracy: 0.2363\n","Train Batch [30/110], Loss: 0.4996, Accuracy: 0.2467\n","Train Batch [40/110], Loss: 0.4966, Accuracy: 0.2570\n","Train Batch [50/110], Loss: 0.4937, Accuracy: 0.2631\n","Train Batch [60/110], Loss: 0.4903, Accuracy: 0.2728\n","Train Batch [70/110], Loss: 0.4874, Accuracy: 0.2813\n","Train Batch [80/110], Loss: 0.4841, Accuracy: 0.2918\n","Train Batch [90/110], Loss: 0.4807, Accuracy: 0.3022\n","Train Batch [100/110], Loss: 0.4773, Accuracy: 0.3125\n","Val Batch [0/32], Loss: 0.4420, Accuracy: 0.7771\n","Val Batch [10/32], Loss: 0.4396, Accuracy: 0.7659\n","Val Batch [20/32], Loss: 0.4397, Accuracy: 0.7616\n","Val Batch [30/32], Loss: 0.4396, Accuracy: 0.7700\n","Epoch [3/10], Train Loss: 0.4746, Train Accuracy: 0.3207, Val Loss: 0.4392, Val Accuracy: 0.7702\n","Epoch [4/10]\n","Train Batch [0/110], Loss: 0.4365, Accuracy: 0.4502\n","Train Batch [10/110], Loss: 0.4359, Accuracy: 0.4448\n","Train Batch [20/110], Loss: 0.4344, Accuracy: 0.4490\n","Train Batch [30/110], Loss: 0.4329, Accuracy: 0.4510\n","Train Batch [40/110], Loss: 0.4297, Accuracy: 0.4679\n","Train Batch [50/110], Loss: 0.4267, Accuracy: 0.4843\n","Train Batch [60/110], Loss: 0.4242, Accuracy: 0.4908\n","Train Batch [70/110], Loss: 0.4218, Accuracy: 0.5005\n","Train Batch [80/110], Loss: 0.4191, Accuracy: 0.5113\n","Train Batch [90/110], Loss: 0.4165, Accuracy: 0.5223\n","Train Batch [100/110], Loss: 0.4141, Accuracy: 0.5309\n","Val Batch [0/32], Loss: 0.3909, Accuracy: 0.7816\n","Val Batch [10/32], Loss: 0.3845, Accuracy: 0.7914\n","Val Batch [20/32], Loss: 0.3843, Accuracy: 0.7871\n","Val Batch [30/32], Loss: 0.3848, Accuracy: 0.7869\n","Epoch [4/10], Train Loss: 0.4118, Train Accuracy: 0.5403, Val Loss: 0.3853, Val Accuracy: 0.7861\n","Epoch [5/10]\n","Train Batch [0/110], Loss: 0.3857, Accuracy: 0.5981\n","Train Batch [10/110], Loss: 0.3813, Accuracy: 0.6176\n","Train Batch [20/110], Loss: 0.3782, Accuracy: 0.6467\n","Train Batch [30/110], Loss: 0.3777, Accuracy: 0.6540\n","Train Batch [40/110], Loss: 0.3758, Accuracy: 0.6570\n","Train Batch [50/110], Loss: 0.3739, Accuracy: 0.6610\n","Train Batch [60/110], Loss: 0.3723, Accuracy: 0.6641\n","Train Batch [70/110], Loss: 0.3700, Accuracy: 0.6695\n","Train Batch [80/110], Loss: 0.3682, Accuracy: 0.6776\n","Train Batch [90/110], Loss: 0.3659, Accuracy: 0.6786\n","Train Batch [100/110], Loss: 0.3640, Accuracy: 0.6832\n","Val Batch [0/32], Loss: 0.3414, Accuracy: 0.8274\n","Val Batch [10/32], Loss: 0.3430, Accuracy: 0.8084\n","Val Batch [20/32], Loss: 0.3422, Accuracy: 0.7971\n","Val Batch [30/32], Loss: 0.3423, Accuracy: 0.7892\n","Epoch [5/10], Train Loss: 0.3622, Train Accuracy: 0.6883, Val Loss: 0.3419, Val Accuracy: 0.7892\n","Epoch [6/10]\n","Train Batch [0/110], Loss: 0.3336, Accuracy: 0.6989\n","Train Batch [10/110], Loss: 0.3385, Accuracy: 0.7286\n","Train Batch [20/110], Loss: 0.3378, Accuracy: 0.7239\n","Train Batch [30/110], Loss: 0.3364, Accuracy: 0.7270\n","Train Batch [40/110], Loss: 0.3345, Accuracy: 0.7292\n","Train Batch [50/110], Loss: 0.3332, Accuracy: 0.7317\n","Train Batch [60/110], Loss: 0.3321, Accuracy: 0.7374\n","Train Batch [70/110], Loss: 0.3304, Accuracy: 0.7368\n","Train Batch [80/110], Loss: 0.3286, Accuracy: 0.7382\n","Train Batch [90/110], Loss: 0.3270, Accuracy: 0.7418\n","Train Batch [100/110], Loss: 0.3252, Accuracy: 0.7423\n","Val Batch [0/32], Loss: 0.3158, Accuracy: 0.7207\n","Val Batch [10/32], Loss: 0.3071, Accuracy: 0.7889\n","Val Batch [20/32], Loss: 0.3076, Accuracy: 0.7912\n","Val Batch [30/32], Loss: 0.3070, Accuracy: 0.7881\n","Epoch [6/10], Train Loss: 0.3237, Train Accuracy: 0.7437, Val Loss: 0.3068, Val Accuracy: 0.7878\n","Epoch [7/10]\n","Train Batch [0/110], Loss: 0.3157, Accuracy: 0.7303\n","Train Batch [10/110], Loss: 0.3049, Accuracy: 0.7557\n","Train Batch [20/110], Loss: 0.3035, Accuracy: 0.7603\n","Train Batch [30/110], Loss: 0.3022, Accuracy: 0.7588\n","Train Batch [40/110], Loss: 0.3004, Accuracy: 0.7619\n","Train Batch [50/110], Loss: 0.2986, Accuracy: 0.7657\n","Train Batch [60/110], Loss: 0.2967, Accuracy: 0.7700\n","Train Batch [70/110], Loss: 0.2950, Accuracy: 0.7712\n","Train Batch [80/110], Loss: 0.2937, Accuracy: 0.7711\n","Train Batch [90/110], Loss: 0.2921, Accuracy: 0.7687\n","Train Batch [100/110], Loss: 0.2908, Accuracy: 0.7686\n","Val Batch [0/32], Loss: 0.2873, Accuracy: 0.7943\n","Val Batch [10/32], Loss: 0.2784, Accuracy: 0.7943\n","Val Batch [20/32], Loss: 0.2783, Accuracy: 0.7913\n","Val Batch [30/32], Loss: 0.2780, Accuracy: 0.7916\n","Epoch [7/10], Train Loss: 0.2899, Train Accuracy: 0.7678, Val Loss: 0.2783, Val Accuracy: 0.7910\n","Epoch [8/10]\n","Train Batch [0/110], Loss: 0.2725, Accuracy: 0.8068\n","Train Batch [10/110], Loss: 0.2700, Accuracy: 0.7824\n","Train Batch [20/110], Loss: 0.2690, Accuracy: 0.7815\n","Train Batch [30/110], Loss: 0.2704, Accuracy: 0.7794\n","Train Batch [40/110], Loss: 0.2696, Accuracy: 0.7805\n","Train Batch [50/110], Loss: 0.2693, Accuracy: 0.7793\n","Train Batch [60/110], Loss: 0.2676, Accuracy: 0.7825\n","Train Batch [70/110], Loss: 0.2671, Accuracy: 0.7797\n","Train Batch [80/110], Loss: 0.2661, Accuracy: 0.7804\n","Train Batch [90/110], Loss: 0.2650, Accuracy: 0.7784\n","Train Batch [100/110], Loss: 0.2643, Accuracy: 0.7772\n","Val Batch [0/32], Loss: 0.2544, Accuracy: 0.8294\n","Val Batch [10/32], Loss: 0.2552, Accuracy: 0.7933\n","Val Batch [20/32], Loss: 0.2542, Accuracy: 0.7942\n","Val Batch [30/32], Loss: 0.2543, Accuracy: 0.7900\n","Epoch [8/10], Train Loss: 0.2633, Train Accuracy: 0.7769, Val Loss: 0.2539, Val Accuracy: 0.7900\n","Epoch [9/10]\n","Train Batch [0/110], Loss: 0.2474, Accuracy: 0.8166\n","Train Batch [10/110], Loss: 0.2495, Accuracy: 0.7805\n","Train Batch [20/110], Loss: 0.2490, Accuracy: 0.7769\n","Train Batch [30/110], Loss: 0.2487, Accuracy: 0.7747\n","Train Batch [40/110], Loss: 0.2468, Accuracy: 0.7716\n","Train Batch [50/110], Loss: 0.2454, Accuracy: 0.7726\n","Train Batch [60/110], Loss: 0.2448, Accuracy: 0.7716\n","Train Batch [70/110], Loss: 0.2439, Accuracy: 0.7741\n","Train Batch [80/110], Loss: 0.2431, Accuracy: 0.7751\n","Train Batch [90/110], Loss: 0.2421, Accuracy: 0.7778\n","Train Batch [100/110], Loss: 0.2413, Accuracy: 0.7771\n","Val Batch [0/32], Loss: 0.2350, Accuracy: 0.7222\n","Val Batch [10/32], Loss: 0.2338, Accuracy: 0.8030\n","Val Batch [20/32], Loss: 0.2346, Accuracy: 0.7934\n","Val Batch [30/32], Loss: 0.2344, Accuracy: 0.7916\n","Epoch [9/10], Train Loss: 0.2405, Train Accuracy: 0.7776, Val Loss: 0.2346, Val Accuracy: 0.7912\n","Epoch [10/10]\n","Train Batch [0/110], Loss: 0.2349, Accuracy: 0.7384\n","Train Batch [10/110], Loss: 0.2312, Accuracy: 0.8010\n","Train Batch [20/110], Loss: 0.2293, Accuracy: 0.8010\n","Train Batch [30/110], Loss: 0.2289, Accuracy: 0.7893\n","Train Batch [40/110], Loss: 0.2279, Accuracy: 0.7859\n","Train Batch [50/110], Loss: 0.2275, Accuracy: 0.7813\n","Train Batch [60/110], Loss: 0.2266, Accuracy: 0.7810\n","Train Batch [70/110], Loss: 0.2259, Accuracy: 0.7807\n","Train Batch [80/110], Loss: 0.2254, Accuracy: 0.7796\n","Train Batch [90/110], Loss: 0.2246, Accuracy: 0.7801\n","Train Batch [100/110], Loss: 0.2236, Accuracy: 0.7802\n","Val Batch [0/32], Loss: 0.2238, Accuracy: 0.7931\n","Val Batch [10/32], Loss: 0.2205, Accuracy: 0.7967\n","Val Batch [20/32], Loss: 0.2188, Accuracy: 0.7921\n","Val Batch [30/32], Loss: 0.2181, Accuracy: 0.7892\n","Epoch [10/10], Train Loss: 0.2229, Train Accuracy: 0.7800, Val Loss: 0.2180, Val Accuracy: 0.7894\n"]},{"output_type":"stream","name":"stderr","text":["Testing:   6%|▋         | 1/16 [00:29<07:17, 29.16s/it]"]},{"output_type":"stream","name":"stdout","text":["Batch 0/16, Current Test Loss: 0.2201, Current Test Accuracy: 0.8103\n"]},{"output_type":"stream","name":"stderr","text":["Testing: 100%|██████████| 16/16 [07:32<00:00, 28.27s/it]"]},{"output_type":"stream","name":"stdout","text":["Test Loss: 0.2178, Test Accuracy: 0.7985\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["train_loader, val_loader, test_loader = create_loaders(train_path=\"/content/drive/Shareddrives/CIS5190FinalProj/Train5000_0.75\",\n","                                                       val_path=\"/content/drive/Shareddrives/CIS5190FinalProj/Val5000_0.75\",\n","                                                       test_path=\"/content/drive/Shareddrives/CIS5190FinalProj/test_dataset\")\n","model, criterion, optimizer = init_vgg19_hyperparameters()\n","\n","## Train the model\n","vgg_train_losses_5000_75, vgg_train_accuracies_5000_75, vgg_val_losses_5000_75, vgg_val_accuracies_5000_75 = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=NUM_EPOCHS)\n","\n","## Test the model\n","vgg_test_loss_5000_75, vgg_test_accuracy_5000_75 = test_model(model, test_loader, criterion)\n","\n","## Save the model\n","torch.save(model.state_dict(), '/content/drive/Shareddrives/CIS5190FinalProj/vgg_5000_75.pth')"]},{"cell_type":"code","source":["save_to_csv(\"/content/drive/Shareddrives/CIS5190FinalProj/results2.csv\",\n","            \"VGG 5000 0.75\",\n","            vgg_train_losses_5000_75,\n","            vgg_train_accuracies_5000_75,\n","            vgg_val_losses_5000_75,\n","            vgg_val_accuracies_5000_75,\n","            vgg_test_loss_5000_75,\n","            vgg_test_accuracy_5000_75)"],"metadata":{"id":"hPT0pdEJq__B"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NRghaBO-4v2v"},"source":["## 5000, 1.0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y13QDxCq48b1","colab":{"base_uri":"https://localhost:8080/"},"outputId":"818e66d4-dc9d-4e86-a0ca-183b2999b3d6"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/10]\n","Train Batch [0/110], Loss: 0.6950, Accuracy: 0.0393\n"]}],"source":["train_loader, val_loader, test_loader = create_loaders(train_path=\"/content/drive/Shareddrives/CIS5190FinalProj/Train5000_1.0\",\n","                                                       val_path=\"/content/drive/Shareddrives/CIS5190FinalProj/Val5000_1.0\",\n","                                                       test_path=\"/content/drive/Shareddrives/CIS5190FinalProj/test_dataset\")\n","model, criterion, optimizer = init_vgg19_hyperparameters()\n","\n","## Train the model\n","vgg_train_losses_5000_100, vgg_train_accuracies_5000_100, vgg_val_losses_5000_100, vgg_val_accuracies_5000_100 = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=NUM_EPOCHS)\n","\n","## Test the model\n","vgg_test_loss_5000_100, vgg_test_accuracy_5000_100 = test_model(model, test_loader, criterion)\n","\n","## Save the model\n","torch.save(model.state_dict(), '/content/drive/Shareddrives/CIS5190FinalProj/vgg_5000_100.pth')"]},{"cell_type":"code","source":["save_to_csv(\"/content/drive/Shareddrives/CIS5190FinalProj/results2.csv\",\n","            \"VGG 5000 1.00\",\n","            vgg_train_losses_5000_100,\n","            vgg_train_accuracies_5000_100,\n","            vgg_val_losses_5000_100,\n","            vgg_val_accuracies_5000_100,\n","            vgg_test_loss_5000_100,\n","            vgg_test_accuracy_5000_100)"],"metadata":{"id":"rhsHH73XrE_C"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ef-TuulK4x9C"},"source":["## 10000, 0.5"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VKO7xTWq48qT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715792979021,"user_tz":-480,"elapsed":4481354,"user":{"displayName":"Matthew Kuo","userId":"14047253604617125631"}},"outputId":"b20b238e-cdec-4d96-a4b1-4e3e3875142d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/10]\n","Train Batch [0/219], Loss: 0.7129, Accuracy: 0.0293\n","Train Batch [10/219], Loss: 0.7103, Accuracy: 0.0255\n","Train Batch [20/219], Loss: 0.7072, Accuracy: 0.0251\n","Train Batch [30/219], Loss: 0.7027, Accuracy: 0.0259\n","Train Batch [40/219], Loss: 0.6976, Accuracy: 0.0268\n","Train Batch [50/219], Loss: 0.6921, Accuracy: 0.0277\n","Train Batch [60/219], Loss: 0.6865, Accuracy: 0.0287\n","Train Batch [70/219], Loss: 0.6810, Accuracy: 0.0301\n","Train Batch [80/219], Loss: 0.6754, Accuracy: 0.0315\n","Train Batch [90/219], Loss: 0.6700, Accuracy: 0.0334\n","Train Batch [100/219], Loss: 0.6646, Accuracy: 0.0351\n","Train Batch [110/219], Loss: 0.6593, Accuracy: 0.0375\n","Train Batch [120/219], Loss: 0.6542, Accuracy: 0.0393\n","Train Batch [130/219], Loss: 0.6491, Accuracy: 0.0413\n","Train Batch [140/219], Loss: 0.6441, Accuracy: 0.0435\n","Train Batch [150/219], Loss: 0.6393, Accuracy: 0.0459\n","Train Batch [160/219], Loss: 0.6344, Accuracy: 0.0488\n","Train Batch [170/219], Loss: 0.6297, Accuracy: 0.0516\n","Train Batch [180/219], Loss: 0.6251, Accuracy: 0.0550\n","Train Batch [190/219], Loss: 0.6203, Accuracy: 0.0586\n","Train Batch [200/219], Loss: 0.6158, Accuracy: 0.0621\n","Train Batch [210/219], Loss: 0.6112, Accuracy: 0.0659\n","Val Batch [0/63], Loss: 0.5050, Accuracy: 0.3583\n","Val Batch [10/63], Loss: 0.5051, Accuracy: 0.4109\n","Val Batch [20/63], Loss: 0.5057, Accuracy: 0.4299\n","Val Batch [30/63], Loss: 0.5057, Accuracy: 0.4266\n","Val Batch [40/63], Loss: 0.5055, Accuracy: 0.4258\n","Val Batch [50/63], Loss: 0.5059, Accuracy: 0.4261\n","Val Batch [60/63], Loss: 0.5056, Accuracy: 0.4307\n","Epoch [1/10], Train Loss: 0.6076, Train Accuracy: 0.0692, Val Loss: 0.5057, Val Accuracy: 0.4300\n","Epoch [2/10]\n","Train Batch [0/219], Loss: 0.5095, Accuracy: 0.1547\n","Train Batch [10/219], Loss: 0.5088, Accuracy: 0.1691\n","Train Batch [20/219], Loss: 0.5042, Accuracy: 0.1707\n","Train Batch [30/219], Loss: 0.5007, Accuracy: 0.1841\n","Train Batch [40/219], Loss: 0.4964, Accuracy: 0.1928\n","Train Batch [50/219], Loss: 0.4928, Accuracy: 0.2006\n","Train Batch [60/219], Loss: 0.4896, Accuracy: 0.2066\n","Train Batch [70/219], Loss: 0.4861, Accuracy: 0.2155\n","Train Batch [80/219], Loss: 0.4830, Accuracy: 0.2227\n","Train Batch [90/219], Loss: 0.4798, Accuracy: 0.2319\n","Train Batch [100/219], Loss: 0.4767, Accuracy: 0.2411\n","Train Batch [110/219], Loss: 0.4736, Accuracy: 0.2517\n","Train Batch [120/219], Loss: 0.4705, Accuracy: 0.2618\n","Train Batch [130/219], Loss: 0.4671, Accuracy: 0.2724\n","Train Batch [140/219], Loss: 0.4639, Accuracy: 0.2822\n","Train Batch [150/219], Loss: 0.4609, Accuracy: 0.2910\n","Train Batch [160/219], Loss: 0.4578, Accuracy: 0.2997\n","Train Batch [170/219], Loss: 0.4551, Accuracy: 0.3091\n","Train Batch [180/219], Loss: 0.4523, Accuracy: 0.3179\n","Train Batch [190/219], Loss: 0.4494, Accuracy: 0.3275\n","Train Batch [200/219], Loss: 0.4467, Accuracy: 0.3364\n","Train Batch [210/219], Loss: 0.4441, Accuracy: 0.3435\n","Val Batch [0/63], Loss: 0.3775, Accuracy: 0.7453\n","Val Batch [10/63], Loss: 0.3820, Accuracy: 0.6844\n","Val Batch [20/63], Loss: 0.3829, Accuracy: 0.6887\n","Val Batch [30/63], Loss: 0.3836, Accuracy: 0.6901\n","Val Batch [40/63], Loss: 0.3832, Accuracy: 0.6922\n","Val Batch [50/63], Loss: 0.3832, Accuracy: 0.6922\n","Val Batch [60/63], Loss: 0.3830, Accuracy: 0.6919\n","Epoch [2/10], Train Loss: 0.4420, Train Accuracy: 0.3504, Val Loss: 0.3831, Val Accuracy: 0.6929\n","Epoch [3/10]\n","Train Batch [0/219], Loss: 0.3825, Accuracy: 0.5765\n","Train Batch [10/219], Loss: 0.3803, Accuracy: 0.5527\n","Train Batch [20/219], Loss: 0.3785, Accuracy: 0.5687\n","Train Batch [30/219], Loss: 0.3766, Accuracy: 0.5683\n","Train Batch [40/219], Loss: 0.3758, Accuracy: 0.5638\n","Train Batch [50/219], Loss: 0.3734, Accuracy: 0.5677\n","Train Batch [60/219], Loss: 0.3715, Accuracy: 0.5730\n","Train Batch [70/219], Loss: 0.3696, Accuracy: 0.5809\n","Train Batch [80/219], Loss: 0.3678, Accuracy: 0.5851\n","Train Batch [90/219], Loss: 0.3656, Accuracy: 0.5885\n","Train Batch [100/219], Loss: 0.3634, Accuracy: 0.5906\n","Train Batch [110/219], Loss: 0.3614, Accuracy: 0.5961\n","Train Batch [120/219], Loss: 0.3593, Accuracy: 0.5991\n","Train Batch [130/219], Loss: 0.3573, Accuracy: 0.6022\n","Train Batch [140/219], Loss: 0.3553, Accuracy: 0.6042\n","Train Batch [150/219], Loss: 0.3536, Accuracy: 0.6068\n","Train Batch [160/219], Loss: 0.3518, Accuracy: 0.6101\n","Train Batch [170/219], Loss: 0.3499, Accuracy: 0.6120\n","Train Batch [180/219], Loss: 0.3480, Accuracy: 0.6131\n","Train Batch [190/219], Loss: 0.3463, Accuracy: 0.6161\n","Train Batch [200/219], Loss: 0.3446, Accuracy: 0.6185\n","Train Batch [210/219], Loss: 0.3429, Accuracy: 0.6206\n","Val Batch [0/63], Loss: 0.3071, Accuracy: 0.6744\n","Val Batch [10/63], Loss: 0.3051, Accuracy: 0.6905\n","Val Batch [20/63], Loss: 0.3040, Accuracy: 0.6797\n","Val Batch [30/63], Loss: 0.3037, Accuracy: 0.6915\n","Val Batch [40/63], Loss: 0.3038, Accuracy: 0.6944\n","Val Batch [50/63], Loss: 0.3047, Accuracy: 0.6956\n","Val Batch [60/63], Loss: 0.3049, Accuracy: 0.6968\n","Epoch [3/10], Train Loss: 0.3416, Train Accuracy: 0.6223, Val Loss: 0.3052, Val Accuracy: 0.6962\n","Epoch [4/10]\n","Train Batch [0/219], Loss: 0.3051, Accuracy: 0.6420\n","Train Batch [10/219], Loss: 0.3031, Accuracy: 0.6701\n","Train Batch [20/219], Loss: 0.3024, Accuracy: 0.6745\n","Train Batch [30/219], Loss: 0.3006, Accuracy: 0.6845\n","Train Batch [40/219], Loss: 0.2998, Accuracy: 0.6790\n","Train Batch [50/219], Loss: 0.2980, Accuracy: 0.6797\n","Train Batch [60/219], Loss: 0.2965, Accuracy: 0.6779\n","Train Batch [70/219], Loss: 0.2951, Accuracy: 0.6798\n","Train Batch [80/219], Loss: 0.2943, Accuracy: 0.6807\n","Train Batch [90/219], Loss: 0.2930, Accuracy: 0.6827\n","Train Batch [100/219], Loss: 0.2919, Accuracy: 0.6802\n","Train Batch [110/219], Loss: 0.2902, Accuracy: 0.6794\n","Train Batch [120/219], Loss: 0.2891, Accuracy: 0.6791\n","Train Batch [130/219], Loss: 0.2877, Accuracy: 0.6785\n","Train Batch [140/219], Loss: 0.2864, Accuracy: 0.6794\n","Train Batch [150/219], Loss: 0.2848, Accuracy: 0.6819\n","Train Batch [160/219], Loss: 0.2834, Accuracy: 0.6827\n","Train Batch [170/219], Loss: 0.2821, Accuracy: 0.6826\n","Train Batch [180/219], Loss: 0.2811, Accuracy: 0.6836\n","Train Batch [190/219], Loss: 0.2799, Accuracy: 0.6824\n","Train Batch [200/219], Loss: 0.2788, Accuracy: 0.6821\n","Train Batch [210/219], Loss: 0.2776, Accuracy: 0.6833\n","Val Batch [0/63], Loss: 0.2594, Accuracy: 0.7532\n","Val Batch [10/63], Loss: 0.2559, Accuracy: 0.6830\n","Val Batch [20/63], Loss: 0.2549, Accuracy: 0.6874\n","Val Batch [30/63], Loss: 0.2549, Accuracy: 0.6950\n","Val Batch [40/63], Loss: 0.2550, Accuracy: 0.6947\n","Val Batch [50/63], Loss: 0.2550, Accuracy: 0.6947\n","Val Batch [60/63], Loss: 0.2550, Accuracy: 0.6970\n","Epoch [4/10], Train Loss: 0.2767, Train Accuracy: 0.6835, Val Loss: 0.2549, Val Accuracy: 0.6976\n","Epoch [5/10]\n","Train Batch [0/219], Loss: 0.2398, Accuracy: 0.6954\n","Train Batch [10/219], Loss: 0.2509, Accuracy: 0.6909\n","Train Batch [20/219], Loss: 0.2501, Accuracy: 0.6750\n","Train Batch [30/219], Loss: 0.2487, Accuracy: 0.6825\n","Train Batch [40/219], Loss: 0.2488, Accuracy: 0.6836\n","Train Batch [50/219], Loss: 0.2479, Accuracy: 0.6889\n","Train Batch [60/219], Loss: 0.2476, Accuracy: 0.6902\n","Train Batch [70/219], Loss: 0.2461, Accuracy: 0.6890\n","Train Batch [80/219], Loss: 0.2450, Accuracy: 0.6878\n","Train Batch [90/219], Loss: 0.2444, Accuracy: 0.6879\n","Train Batch [100/219], Loss: 0.2433, Accuracy: 0.6880\n","Train Batch [110/219], Loss: 0.2427, Accuracy: 0.6866\n","Train Batch [120/219], Loss: 0.2417, Accuracy: 0.6898\n","Train Batch [130/219], Loss: 0.2408, Accuracy: 0.6896\n","Train Batch [140/219], Loss: 0.2400, Accuracy: 0.6918\n","Train Batch [150/219], Loss: 0.2392, Accuracy: 0.6929\n","Train Batch [160/219], Loss: 0.2383, Accuracy: 0.6934\n","Train Batch [170/219], Loss: 0.2374, Accuracy: 0.6942\n","Train Batch [180/219], Loss: 0.2367, Accuracy: 0.6944\n","Train Batch [190/219], Loss: 0.2358, Accuracy: 0.6939\n","Train Batch [200/219], Loss: 0.2350, Accuracy: 0.6939\n","Train Batch [210/219], Loss: 0.2342, Accuracy: 0.6935\n","Val Batch [0/63], Loss: 0.2225, Accuracy: 0.6481\n","Val Batch [10/63], Loss: 0.2185, Accuracy: 0.7018\n","Val Batch [20/63], Loss: 0.2187, Accuracy: 0.6984\n","Val Batch [30/63], Loss: 0.2191, Accuracy: 0.7017\n","Val Batch [40/63], Loss: 0.2182, Accuracy: 0.7010\n","Val Batch [50/63], Loss: 0.2189, Accuracy: 0.6986\n","Val Batch [60/63], Loss: 0.2186, Accuracy: 0.6992\n","Epoch [5/10], Train Loss: 0.2335, Train Accuracy: 0.6941, Val Loss: 0.2186, Val Accuracy: 0.6992\n","Epoch [6/10]\n","Train Batch [0/219], Loss: 0.2263, Accuracy: 0.7888\n","Train Batch [10/219], Loss: 0.2170, Accuracy: 0.7004\n","Train Batch [20/219], Loss: 0.2154, Accuracy: 0.6990\n","Train Batch [30/219], Loss: 0.2153, Accuracy: 0.6944\n","Train Batch [40/219], Loss: 0.2157, Accuracy: 0.6893\n","Train Batch [50/219], Loss: 0.2148, Accuracy: 0.6904\n","Train Batch [60/219], Loss: 0.2130, Accuracy: 0.6911\n","Train Batch [70/219], Loss: 0.2121, Accuracy: 0.6886\n","Train Batch [80/219], Loss: 0.2113, Accuracy: 0.6902\n","Train Batch [90/219], Loss: 0.2105, Accuracy: 0.6902\n","Train Batch [100/219], Loss: 0.2099, Accuracy: 0.6915\n","Train Batch [110/219], Loss: 0.2093, Accuracy: 0.6911\n","Train Batch [120/219], Loss: 0.2087, Accuracy: 0.6935\n","Train Batch [130/219], Loss: 0.2078, Accuracy: 0.6950\n","Train Batch [140/219], Loss: 0.2074, Accuracy: 0.6952\n","Train Batch [150/219], Loss: 0.2069, Accuracy: 0.6955\n","Train Batch [160/219], Loss: 0.2064, Accuracy: 0.6958\n","Train Batch [170/219], Loss: 0.2057, Accuracy: 0.6951\n","Train Batch [180/219], Loss: 0.2048, Accuracy: 0.6959\n","Train Batch [190/219], Loss: 0.2041, Accuracy: 0.6966\n","Train Batch [200/219], Loss: 0.2034, Accuracy: 0.6961\n","Train Batch [210/219], Loss: 0.2028, Accuracy: 0.6959\n","Val Batch [0/63], Loss: 0.1900, Accuracy: 0.7658\n","Val Batch [10/63], Loss: 0.1910, Accuracy: 0.7061\n","Val Batch [20/63], Loss: 0.1921, Accuracy: 0.6936\n","Val Batch [30/63], Loss: 0.1923, Accuracy: 0.6988\n","Val Batch [40/63], Loss: 0.1916, Accuracy: 0.7007\n","Val Batch [50/63], Loss: 0.1915, Accuracy: 0.6992\n","Val Batch [60/63], Loss: 0.1914, Accuracy: 0.6983\n","Epoch [6/10], Train Loss: 0.2023, Train Accuracy: 0.6953, Val Loss: 0.1915, Val Accuracy: 0.6990\n","Epoch [7/10]\n","Train Batch [0/219], Loss: 0.1970, Accuracy: 0.7176\n","Train Batch [10/219], Loss: 0.1920, Accuracy: 0.7003\n","Train Batch [20/219], Loss: 0.1893, Accuracy: 0.6990\n","Train Batch [30/219], Loss: 0.1881, Accuracy: 0.6892\n","Train Batch [40/219], Loss: 0.1876, Accuracy: 0.6944\n","Train Batch [50/219], Loss: 0.1873, Accuracy: 0.6961\n","Train Batch [60/219], Loss: 0.1868, Accuracy: 0.6963\n","Train Batch [70/219], Loss: 0.1865, Accuracy: 0.6976\n","Train Batch [80/219], Loss: 0.1858, Accuracy: 0.6988\n","Train Batch [90/219], Loss: 0.1855, Accuracy: 0.6972\n","Train Batch [100/219], Loss: 0.1850, Accuracy: 0.6961\n","Train Batch [110/219], Loss: 0.1845, Accuracy: 0.6960\n","Train Batch [120/219], Loss: 0.1839, Accuracy: 0.6978\n","Train Batch [130/219], Loss: 0.1838, Accuracy: 0.6974\n","Train Batch [140/219], Loss: 0.1833, Accuracy: 0.6972\n","Train Batch [150/219], Loss: 0.1829, Accuracy: 0.6972\n","Train Batch [160/219], Loss: 0.1823, Accuracy: 0.6985\n","Train Batch [170/219], Loss: 0.1819, Accuracy: 0.6986\n","Train Batch [180/219], Loss: 0.1813, Accuracy: 0.6985\n","Train Batch [190/219], Loss: 0.1807, Accuracy: 0.6995\n","Train Batch [200/219], Loss: 0.1804, Accuracy: 0.6999\n","Train Batch [210/219], Loss: 0.1799, Accuracy: 0.6993\n","Val Batch [0/63], Loss: 0.1815, Accuracy: 0.6957\n","Val Batch [10/63], Loss: 0.1734, Accuracy: 0.6937\n","Val Batch [20/63], Loss: 0.1719, Accuracy: 0.7045\n","Val Batch [30/63], Loss: 0.1719, Accuracy: 0.6998\n","Val Batch [40/63], Loss: 0.1716, Accuracy: 0.7012\n","Val Batch [50/63], Loss: 0.1717, Accuracy: 0.7016\n","Val Batch [60/63], Loss: 0.1718, Accuracy: 0.7000\n","Epoch [7/10], Train Loss: 0.1796, Train Accuracy: 0.6992, Val Loss: 0.1718, Val Accuracy: 0.6995\n","Epoch [8/10]\n","Train Batch [0/219], Loss: 0.1826, Accuracy: 0.7310\n","Train Batch [10/219], Loss: 0.1715, Accuracy: 0.7073\n","Train Batch [20/219], Loss: 0.1708, Accuracy: 0.7045\n","Train Batch [30/219], Loss: 0.1706, Accuracy: 0.7018\n","Train Batch [40/219], Loss: 0.1696, Accuracy: 0.7032\n","Train Batch [50/219], Loss: 0.1684, Accuracy: 0.7050\n","Train Batch [60/219], Loss: 0.1681, Accuracy: 0.7019\n","Train Batch [70/219], Loss: 0.1674, Accuracy: 0.7005\n","Train Batch [80/219], Loss: 0.1670, Accuracy: 0.6996\n","Train Batch [90/219], Loss: 0.1663, Accuracy: 0.7022\n","Train Batch [100/219], Loss: 0.1663, Accuracy: 0.7014\n","Train Batch [110/219], Loss: 0.1659, Accuracy: 0.6993\n","Train Batch [120/219], Loss: 0.1656, Accuracy: 0.6989\n","Train Batch [130/219], Loss: 0.1653, Accuracy: 0.6979\n","Train Batch [140/219], Loss: 0.1650, Accuracy: 0.6986\n","Train Batch [150/219], Loss: 0.1645, Accuracy: 0.7005\n","Train Batch [160/219], Loss: 0.1641, Accuracy: 0.7008\n","Train Batch [170/219], Loss: 0.1639, Accuracy: 0.6998\n","Train Batch [180/219], Loss: 0.1636, Accuracy: 0.6992\n","Train Batch [190/219], Loss: 0.1632, Accuracy: 0.6993\n","Train Batch [200/219], Loss: 0.1627, Accuracy: 0.7000\n","Train Batch [210/219], Loss: 0.1623, Accuracy: 0.6991\n","Val Batch [0/63], Loss: 0.1599, Accuracy: 0.6810\n","Val Batch [10/63], Loss: 0.1542, Accuracy: 0.7065\n","Val Batch [20/63], Loss: 0.1552, Accuracy: 0.7064\n","Val Batch [30/63], Loss: 0.1555, Accuracy: 0.7037\n","Val Batch [40/63], Loss: 0.1559, Accuracy: 0.7034\n","Val Batch [50/63], Loss: 0.1560, Accuracy: 0.7019\n","Val Batch [60/63], Loss: 0.1558, Accuracy: 0.7017\n","Epoch [8/10], Train Loss: 0.1622, Train Accuracy: 0.6996, Val Loss: 0.1558, Val Accuracy: 0.7009\n","Epoch [9/10]\n","Train Batch [0/219], Loss: 0.1575, Accuracy: 0.6243\n","Train Batch [10/219], Loss: 0.1564, Accuracy: 0.6833\n","Train Batch [20/219], Loss: 0.1544, Accuracy: 0.6982\n","Train Batch [30/219], Loss: 0.1545, Accuracy: 0.6947\n","Train Batch [40/219], Loss: 0.1540, Accuracy: 0.6950\n","Train Batch [50/219], Loss: 0.1533, Accuracy: 0.6958\n","Train Batch [60/219], Loss: 0.1533, Accuracy: 0.6951\n","Train Batch [70/219], Loss: 0.1532, Accuracy: 0.6969\n","Train Batch [80/219], Loss: 0.1528, Accuracy: 0.6985\n","Train Batch [90/219], Loss: 0.1526, Accuracy: 0.6999\n","Train Batch [100/219], Loss: 0.1524, Accuracy: 0.7008\n","Train Batch [110/219], Loss: 0.1520, Accuracy: 0.6988\n","Train Batch [120/219], Loss: 0.1514, Accuracy: 0.7001\n","Train Batch [130/219], Loss: 0.1512, Accuracy: 0.6982\n","Train Batch [140/219], Loss: 0.1507, Accuracy: 0.6993\n","Train Batch [150/219], Loss: 0.1503, Accuracy: 0.6989\n","Train Batch [160/219], Loss: 0.1500, Accuracy: 0.6993\n","Train Batch [170/219], Loss: 0.1498, Accuracy: 0.6995\n","Train Batch [180/219], Loss: 0.1494, Accuracy: 0.7000\n","Train Batch [190/219], Loss: 0.1489, Accuracy: 0.7005\n","Train Batch [200/219], Loss: 0.1486, Accuracy: 0.6998\n","Train Batch [210/219], Loss: 0.1482, Accuracy: 0.7001\n","Val Batch [0/63], Loss: 0.1382, Accuracy: 0.7152\n","Val Batch [10/63], Loss: 0.1441, Accuracy: 0.6961\n","Val Batch [20/63], Loss: 0.1429, Accuracy: 0.6923\n","Val Batch [30/63], Loss: 0.1431, Accuracy: 0.6937\n","Val Batch [40/63], Loss: 0.1427, Accuracy: 0.7000\n","Val Batch [50/63], Loss: 0.1422, Accuracy: 0.7018\n","Val Batch [60/63], Loss: 0.1424, Accuracy: 0.7013\n","Epoch [9/10], Train Loss: 0.1479, Train Accuracy: 0.7000, Val Loss: 0.1426, Val Accuracy: 0.6997\n","Epoch [10/10]\n","Train Batch [0/219], Loss: 0.1431, Accuracy: 0.6964\n","Train Batch [10/219], Loss: 0.1423, Accuracy: 0.7110\n","Train Batch [20/219], Loss: 0.1419, Accuracy: 0.6973\n","Train Batch [30/219], Loss: 0.1410, Accuracy: 0.7028\n","Train Batch [40/219], Loss: 0.1400, Accuracy: 0.7030\n","Train Batch [50/219], Loss: 0.1399, Accuracy: 0.7017\n","Train Batch [60/219], Loss: 0.1394, Accuracy: 0.7009\n","Train Batch [70/219], Loss: 0.1394, Accuracy: 0.7013\n","Train Batch [80/219], Loss: 0.1390, Accuracy: 0.7016\n","Train Batch [90/219], Loss: 0.1392, Accuracy: 0.6982\n","Train Batch [100/219], Loss: 0.1387, Accuracy: 0.6982\n","Train Batch [110/219], Loss: 0.1385, Accuracy: 0.6986\n","Train Batch [120/219], Loss: 0.1383, Accuracy: 0.6973\n","Train Batch [130/219], Loss: 0.1382, Accuracy: 0.6974\n","Train Batch [140/219], Loss: 0.1380, Accuracy: 0.6992\n","Train Batch [150/219], Loss: 0.1377, Accuracy: 0.7000\n","Train Batch [160/219], Loss: 0.1375, Accuracy: 0.7008\n","Train Batch [170/219], Loss: 0.1371, Accuracy: 0.7011\n","Train Batch [180/219], Loss: 0.1367, Accuracy: 0.7013\n","Train Batch [190/219], Loss: 0.1366, Accuracy: 0.7011\n","Train Batch [200/219], Loss: 0.1365, Accuracy: 0.7001\n","Train Batch [210/219], Loss: 0.1362, Accuracy: 0.6990\n","Val Batch [0/63], Loss: 0.1381, Accuracy: 0.6807\n","Val Batch [10/63], Loss: 0.1325, Accuracy: 0.7163\n","Val Batch [20/63], Loss: 0.1328, Accuracy: 0.7137\n","Val Batch [30/63], Loss: 0.1332, Accuracy: 0.7081\n","Val Batch [40/63], Loss: 0.1330, Accuracy: 0.7044\n","Val Batch [50/63], Loss: 0.1329, Accuracy: 0.7033\n","Val Batch [60/63], Loss: 0.1332, Accuracy: 0.7018\n","Epoch [10/10], Train Loss: 0.1359, Train Accuracy: 0.6996, Val Loss: 0.1334, Val Accuracy: 0.7024\n"]},{"output_type":"stream","name":"stderr","text":["Testing:   3%|▎         | 1/32 [00:28<14:56, 28.91s/it]"]},{"output_type":"stream","name":"stdout","text":["Batch 0/32, Current Test Loss: 0.1402, Current Test Accuracy: 0.7099\n"]},{"output_type":"stream","name":"stderr","text":["Testing: 100%|██████████| 32/32 [15:00<00:00, 28.15s/it]"]},{"output_type":"stream","name":"stdout","text":["Test Loss: 0.1347, Test Accuracy: 0.6952\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["train_loader, val_loader, test_loader = create_loaders(train_path=\"/content/drive/Shareddrives/CIS5190FinalProj/Train10000_0.5\",\n","                                                       val_path=\"/content/drive/Shareddrives/CIS5190FinalProj/Val10000_0.5\",\n","                                                       test_path=\"/content/drive/Shareddrives/CIS5190FinalProj/test_dataset\")\n","model, criterion, optimizer = init_vgg19_hyperparameters()\n","\n","## Train the model\n","vgg_train_losses_10000_50, vgg_train_accuracies_10000_50, vgg_val_losses_10000_50, vgg_val_accuracies_10000_50 = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=NUM_EPOCHS)\n","\n","## Test the model\n","vgg_test_loss_10000_50, vgg_test_accuracy_10000_50 = test_model(model, test_loader, criterion)\n","\n","## Save the model\n","torch.save(model.state_dict(), '/content/drive/Shareddrives/CIS5190FinalProj/vgg_10000_50.pth')"]},{"cell_type":"code","source":["save_to_csv(\"/content/drive/Shareddrives/CIS5190FinalProj/results2.csv\",\n","            \"VGG 10000 0.5\",\n","            vgg_train_losses_10000_50,\n","            vgg_train_accuracies_10000_50,\n","            vgg_val_losses_10000_50,\n","            vgg_val_accuracies_10000_50,\n","            vgg_test_loss_10000_50,\n","            vgg_test_accuracy_10000_50)"],"metadata":{"id":"undlW6WKrKQP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r4NWkFiQ40tJ"},"source":["## 10000, 0.75"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h4KbTdYp485V","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715797239537,"user_tz":-480,"elapsed":4259895,"user":{"displayName":"Matthew Kuo","userId":"14047253604617125631"}},"outputId":"e162ff9e-ebb8-4f26-ada3-8adb9faaf316"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/10]\n","Train Batch [0/219], Loss: 0.6929, Accuracy: 0.0460\n","Train Batch [10/219], Loss: 0.6906, Accuracy: 0.0447\n","Train Batch [20/219], Loss: 0.6869, Accuracy: 0.0450\n","Train Batch [30/219], Loss: 0.6828, Accuracy: 0.0451\n","Train Batch [40/219], Loss: 0.6785, Accuracy: 0.0467\n","Train Batch [50/219], Loss: 0.6732, Accuracy: 0.0483\n","Train Batch [60/219], Loss: 0.6678, Accuracy: 0.0500\n","Train Batch [70/219], Loss: 0.6625, Accuracy: 0.0518\n","Train Batch [80/219], Loss: 0.6577, Accuracy: 0.0540\n","Train Batch [90/219], Loss: 0.6524, Accuracy: 0.0562\n","Train Batch [100/219], Loss: 0.6474, Accuracy: 0.0587\n","Train Batch [110/219], Loss: 0.6425, Accuracy: 0.0613\n","Train Batch [120/219], Loss: 0.6375, Accuracy: 0.0644\n","Train Batch [130/219], Loss: 0.6327, Accuracy: 0.0674\n","Train Batch [140/219], Loss: 0.6279, Accuracy: 0.0706\n","Train Batch [150/219], Loss: 0.6232, Accuracy: 0.0741\n","Train Batch [160/219], Loss: 0.6185, Accuracy: 0.0780\n","Train Batch [170/219], Loss: 0.6140, Accuracy: 0.0817\n","Train Batch [180/219], Loss: 0.6095, Accuracy: 0.0856\n","Train Batch [190/219], Loss: 0.6050, Accuracy: 0.0902\n","Train Batch [200/219], Loss: 0.6008, Accuracy: 0.0947\n","Train Batch [210/219], Loss: 0.5966, Accuracy: 0.0992\n","Val Batch [0/63], Loss: 0.4975, Accuracy: 0.4932\n","Val Batch [10/63], Loss: 0.4968, Accuracy: 0.4915\n","Val Batch [20/63], Loss: 0.4975, Accuracy: 0.4912\n","Val Batch [30/63], Loss: 0.4980, Accuracy: 0.4897\n","Val Batch [40/63], Loss: 0.4983, Accuracy: 0.4848\n","Val Batch [50/63], Loss: 0.4982, Accuracy: 0.4847\n","Val Batch [60/63], Loss: 0.4983, Accuracy: 0.4831\n","Epoch [1/10], Train Loss: 0.5932, Train Accuracy: 0.1031, Val Loss: 0.4982, Val Accuracy: 0.4841\n","Epoch [2/10]\n","Train Batch [0/219], Loss: 0.5024, Accuracy: 0.2180\n","Train Batch [10/219], Loss: 0.4969, Accuracy: 0.2375\n","Train Batch [20/219], Loss: 0.4930, Accuracy: 0.2374\n","Train Batch [30/219], Loss: 0.4907, Accuracy: 0.2443\n","Train Batch [40/219], Loss: 0.4876, Accuracy: 0.2526\n","Train Batch [50/219], Loss: 0.4843, Accuracy: 0.2619\n","Train Batch [60/219], Loss: 0.4809, Accuracy: 0.2700\n","Train Batch [70/219], Loss: 0.4773, Accuracy: 0.2792\n","Train Batch [80/219], Loss: 0.4739, Accuracy: 0.2897\n","Train Batch [90/219], Loss: 0.4709, Accuracy: 0.3008\n","Train Batch [100/219], Loss: 0.4677, Accuracy: 0.3117\n","Train Batch [110/219], Loss: 0.4647, Accuracy: 0.3223\n","Train Batch [120/219], Loss: 0.4617, Accuracy: 0.3327\n","Train Batch [130/219], Loss: 0.4588, Accuracy: 0.3434\n","Train Batch [140/219], Loss: 0.4563, Accuracy: 0.3526\n","Train Batch [150/219], Loss: 0.4533, Accuracy: 0.3634\n","Train Batch [160/219], Loss: 0.4505, Accuracy: 0.3741\n","Train Batch [170/219], Loss: 0.4474, Accuracy: 0.3845\n","Train Batch [180/219], Loss: 0.4449, Accuracy: 0.3939\n","Train Batch [190/219], Loss: 0.4423, Accuracy: 0.4036\n","Train Batch [200/219], Loss: 0.4397, Accuracy: 0.4131\n","Train Batch [210/219], Loss: 0.4370, Accuracy: 0.4224\n","Val Batch [0/63], Loss: 0.3753, Accuracy: 0.7572\n","Val Batch [10/63], Loss: 0.3804, Accuracy: 0.7710\n","Val Batch [20/63], Loss: 0.3807, Accuracy: 0.7738\n","Val Batch [30/63], Loss: 0.3803, Accuracy: 0.7728\n","Val Batch [40/63], Loss: 0.3798, Accuracy: 0.7718\n","Val Batch [50/63], Loss: 0.3797, Accuracy: 0.7716\n","Val Batch [60/63], Loss: 0.3794, Accuracy: 0.7707\n","Epoch [2/10], Train Loss: 0.4350, Train Accuracy: 0.4286, Val Loss: 0.3795, Val Accuracy: 0.7703\n","Epoch [3/10]\n","Train Batch [0/219], Loss: 0.3766, Accuracy: 0.6432\n","Train Batch [10/219], Loss: 0.3742, Accuracy: 0.6137\n","Train Batch [20/219], Loss: 0.3738, Accuracy: 0.6242\n","Train Batch [30/219], Loss: 0.3711, Accuracy: 0.6361\n","Train Batch [40/219], Loss: 0.3694, Accuracy: 0.6419\n","Train Batch [50/219], Loss: 0.3674, Accuracy: 0.6453\n","Train Batch [60/219], Loss: 0.3651, Accuracy: 0.6516\n","Train Batch [70/219], Loss: 0.3628, Accuracy: 0.6587\n","Train Batch [80/219], Loss: 0.3605, Accuracy: 0.6645\n","Train Batch [90/219], Loss: 0.3586, Accuracy: 0.6702\n","Train Batch [100/219], Loss: 0.3570, Accuracy: 0.6744\n","Train Batch [110/219], Loss: 0.3554, Accuracy: 0.6779\n","Train Batch [120/219], Loss: 0.3537, Accuracy: 0.6818\n","Train Batch [130/219], Loss: 0.3517, Accuracy: 0.6861\n","Train Batch [140/219], Loss: 0.3499, Accuracy: 0.6880\n","Train Batch [150/219], Loss: 0.3482, Accuracy: 0.6894\n","Train Batch [160/219], Loss: 0.3465, Accuracy: 0.6934\n","Train Batch [170/219], Loss: 0.3448, Accuracy: 0.6961\n","Train Batch [180/219], Loss: 0.3430, Accuracy: 0.6996\n","Train Batch [190/219], Loss: 0.3414, Accuracy: 0.7020\n","Train Batch [200/219], Loss: 0.3397, Accuracy: 0.7044\n","Train Batch [210/219], Loss: 0.3379, Accuracy: 0.7062\n","Val Batch [0/63], Loss: 0.3093, Accuracy: 0.7904\n","Val Batch [10/63], Loss: 0.3082, Accuracy: 0.7793\n","Val Batch [20/63], Loss: 0.3074, Accuracy: 0.7782\n","Val Batch [30/63], Loss: 0.3057, Accuracy: 0.7833\n","Val Batch [40/63], Loss: 0.3057, Accuracy: 0.7825\n","Val Batch [50/63], Loss: 0.3050, Accuracy: 0.7853\n","Val Batch [60/63], Loss: 0.3050, Accuracy: 0.7826\n","Epoch [3/10], Train Loss: 0.3368, Train Accuracy: 0.7076, Val Loss: 0.3049, Val Accuracy: 0.7828\n","Epoch [4/10]\n","Train Batch [0/219], Loss: 0.2921, Accuracy: 0.7888\n","Train Batch [10/219], Loss: 0.2970, Accuracy: 0.7587\n","Train Batch [20/219], Loss: 0.2975, Accuracy: 0.7521\n","Train Batch [30/219], Loss: 0.2972, Accuracy: 0.7525\n","Train Batch [40/219], Loss: 0.2958, Accuracy: 0.7541\n","Train Batch [50/219], Loss: 0.2942, Accuracy: 0.7586\n","Train Batch [60/219], Loss: 0.2926, Accuracy: 0.7634\n","Train Batch [70/219], Loss: 0.2913, Accuracy: 0.7628\n","Train Batch [80/219], Loss: 0.2903, Accuracy: 0.7631\n","Train Batch [90/219], Loss: 0.2886, Accuracy: 0.7644\n","Train Batch [100/219], Loss: 0.2875, Accuracy: 0.7657\n","Train Batch [110/219], Loss: 0.2863, Accuracy: 0.7671\n","Train Batch [120/219], Loss: 0.2852, Accuracy: 0.7676\n","Train Batch [130/219], Loss: 0.2838, Accuracy: 0.7685\n","Train Batch [140/219], Loss: 0.2824, Accuracy: 0.7698\n","Train Batch [150/219], Loss: 0.2812, Accuracy: 0.7679\n","Train Batch [160/219], Loss: 0.2802, Accuracy: 0.7673\n","Train Batch [170/219], Loss: 0.2791, Accuracy: 0.7683\n","Train Batch [180/219], Loss: 0.2779, Accuracy: 0.7689\n","Train Batch [190/219], Loss: 0.2770, Accuracy: 0.7695\n","Train Batch [200/219], Loss: 0.2761, Accuracy: 0.7697\n","Train Batch [210/219], Loss: 0.2750, Accuracy: 0.7689\n","Val Batch [0/63], Loss: 0.2533, Accuracy: 0.7895\n","Val Batch [10/63], Loss: 0.2521, Accuracy: 0.8022\n","Val Batch [20/63], Loss: 0.2524, Accuracy: 0.7916\n","Val Batch [30/63], Loss: 0.2515, Accuracy: 0.7876\n","Val Batch [40/63], Loss: 0.2529, Accuracy: 0.7878\n","Val Batch [50/63], Loss: 0.2536, Accuracy: 0.7839\n","Val Batch [60/63], Loss: 0.2532, Accuracy: 0.7849\n","Epoch [4/10], Train Loss: 0.2740, Train Accuracy: 0.7690, Val Loss: 0.2533, Val Accuracy: 0.7863\n","Epoch [5/10]\n","Train Batch [0/219], Loss: 0.2455, Accuracy: 0.8598\n","Train Batch [10/219], Loss: 0.2494, Accuracy: 0.7862\n","Train Batch [20/219], Loss: 0.2483, Accuracy: 0.7693\n","Train Batch [30/219], Loss: 0.2483, Accuracy: 0.7718\n","Train Batch [40/219], Loss: 0.2470, Accuracy: 0.7728\n","Train Batch [50/219], Loss: 0.2459, Accuracy: 0.7729\n","Train Batch [60/219], Loss: 0.2447, Accuracy: 0.7763\n","Train Batch [70/219], Loss: 0.2437, Accuracy: 0.7752\n","Train Batch [80/219], Loss: 0.2433, Accuracy: 0.7750\n","Train Batch [90/219], Loss: 0.2426, Accuracy: 0.7763\n","Train Batch [100/219], Loss: 0.2413, Accuracy: 0.7763\n","Train Batch [110/219], Loss: 0.2403, Accuracy: 0.7771\n","Train Batch [120/219], Loss: 0.2392, Accuracy: 0.7769\n","Train Batch [130/219], Loss: 0.2383, Accuracy: 0.7769\n","Train Batch [140/219], Loss: 0.2373, Accuracy: 0.7755\n","Train Batch [150/219], Loss: 0.2366, Accuracy: 0.7760\n","Train Batch [160/219], Loss: 0.2357, Accuracy: 0.7759\n","Train Batch [170/219], Loss: 0.2348, Accuracy: 0.7759\n","Train Batch [180/219], Loss: 0.2340, Accuracy: 0.7765\n","Train Batch [190/219], Loss: 0.2332, Accuracy: 0.7757\n","Train Batch [200/219], Loss: 0.2324, Accuracy: 0.7764\n","Train Batch [210/219], Loss: 0.2316, Accuracy: 0.7773\n","Val Batch [0/63], Loss: 0.2024, Accuracy: 0.8198\n","Val Batch [10/63], Loss: 0.2127, Accuracy: 0.7919\n","Val Batch [20/63], Loss: 0.2152, Accuracy: 0.7850\n","Val Batch [30/63], Loss: 0.2153, Accuracy: 0.7834\n","Val Batch [40/63], Loss: 0.2156, Accuracy: 0.7833\n","Val Batch [50/63], Loss: 0.2158, Accuracy: 0.7882\n","Val Batch [60/63], Loss: 0.2156, Accuracy: 0.7879\n","Epoch [5/10], Train Loss: 0.2311, Train Accuracy: 0.7772, Val Loss: 0.2159, Val Accuracy: 0.7877\n","Epoch [6/10]\n","Train Batch [0/219], Loss: 0.2232, Accuracy: 0.7514\n","Train Batch [10/219], Loss: 0.2121, Accuracy: 0.7798\n","Train Batch [20/219], Loss: 0.2116, Accuracy: 0.7835\n","Train Batch [30/219], Loss: 0.2113, Accuracy: 0.7860\n","Train Batch [40/219], Loss: 0.2104, Accuracy: 0.7878\n","Train Batch [50/219], Loss: 0.2101, Accuracy: 0.7884\n","Train Batch [60/219], Loss: 0.2098, Accuracy: 0.7861\n","Train Batch [70/219], Loss: 0.2089, Accuracy: 0.7826\n","Train Batch [80/219], Loss: 0.2086, Accuracy: 0.7800\n","Train Batch [90/219], Loss: 0.2077, Accuracy: 0.7788\n","Train Batch [100/219], Loss: 0.2069, Accuracy: 0.7818\n","Train Batch [110/219], Loss: 0.2061, Accuracy: 0.7807\n","Train Batch [120/219], Loss: 0.2056, Accuracy: 0.7803\n","Train Batch [130/219], Loss: 0.2050, Accuracy: 0.7802\n","Train Batch [140/219], Loss: 0.2043, Accuracy: 0.7810\n","Train Batch [150/219], Loss: 0.2037, Accuracy: 0.7819\n","Train Batch [160/219], Loss: 0.2031, Accuracy: 0.7827\n","Train Batch [170/219], Loss: 0.2024, Accuracy: 0.7829\n","Train Batch [180/219], Loss: 0.2019, Accuracy: 0.7823\n","Train Batch [190/219], Loss: 0.2014, Accuracy: 0.7816\n","Train Batch [200/219], Loss: 0.2007, Accuracy: 0.7820\n","Train Batch [210/219], Loss: 0.2000, Accuracy: 0.7819\n","Val Batch [0/63], Loss: 0.1854, Accuracy: 0.8353\n","Val Batch [10/63], Loss: 0.1867, Accuracy: 0.7914\n","Val Batch [20/63], Loss: 0.1885, Accuracy: 0.7957\n","Val Batch [30/63], Loss: 0.1884, Accuracy: 0.7906\n","Val Batch [40/63], Loss: 0.1900, Accuracy: 0.7898\n","Val Batch [50/63], Loss: 0.1895, Accuracy: 0.7905\n","Val Batch [60/63], Loss: 0.1900, Accuracy: 0.7887\n","Epoch [6/10], Train Loss: 0.1996, Train Accuracy: 0.7821, Val Loss: 0.1900, Val Accuracy: 0.7890\n","Epoch [7/10]\n","Train Batch [0/219], Loss: 0.1897, Accuracy: 0.8107\n","Train Batch [10/219], Loss: 0.1859, Accuracy: 0.7953\n","Train Batch [20/219], Loss: 0.1865, Accuracy: 0.8013\n","Train Batch [30/219], Loss: 0.1861, Accuracy: 0.7912\n","Train Batch [40/219], Loss: 0.1850, Accuracy: 0.7925\n","Train Batch [50/219], Loss: 0.1845, Accuracy: 0.7885\n","Train Batch [60/219], Loss: 0.1838, Accuracy: 0.7876\n","Train Batch [70/219], Loss: 0.1827, Accuracy: 0.7882\n","Train Batch [80/219], Loss: 0.1822, Accuracy: 0.7884\n","Train Batch [90/219], Loss: 0.1815, Accuracy: 0.7860\n","Train Batch [100/219], Loss: 0.1807, Accuracy: 0.7854\n","Train Batch [110/219], Loss: 0.1802, Accuracy: 0.7849\n","Train Batch [120/219], Loss: 0.1800, Accuracy: 0.7831\n","Train Batch [130/219], Loss: 0.1797, Accuracy: 0.7817\n","Train Batch [140/219], Loss: 0.1793, Accuracy: 0.7824\n","Train Batch [150/219], Loss: 0.1786, Accuracy: 0.7829\n","Train Batch [160/219], Loss: 0.1781, Accuracy: 0.7826\n","Train Batch [170/219], Loss: 0.1778, Accuracy: 0.7820\n","Train Batch [180/219], Loss: 0.1773, Accuracy: 0.7816\n","Train Batch [190/219], Loss: 0.1768, Accuracy: 0.7821\n","Train Batch [200/219], Loss: 0.1762, Accuracy: 0.7828\n","Train Batch [210/219], Loss: 0.1758, Accuracy: 0.7827\n","Val Batch [0/63], Loss: 0.1618, Accuracy: 0.8187\n","Val Batch [10/63], Loss: 0.1683, Accuracy: 0.7843\n","Val Batch [20/63], Loss: 0.1686, Accuracy: 0.7943\n","Val Batch [30/63], Loss: 0.1693, Accuracy: 0.7840\n","Val Batch [40/63], Loss: 0.1689, Accuracy: 0.7900\n","Val Batch [50/63], Loss: 0.1690, Accuracy: 0.7901\n","Val Batch [60/63], Loss: 0.1692, Accuracy: 0.7868\n","Epoch [7/10], Train Loss: 0.1753, Train Accuracy: 0.7825, Val Loss: 0.1693, Val Accuracy: 0.7878\n","Epoch [8/10]\n","Train Batch [0/219], Loss: 0.1637, Accuracy: 0.7965\n","Train Batch [10/219], Loss: 0.1623, Accuracy: 0.7858\n","Train Batch [20/219], Loss: 0.1644, Accuracy: 0.7959\n","Train Batch [30/219], Loss: 0.1655, Accuracy: 0.7876\n","Train Batch [40/219], Loss: 0.1647, Accuracy: 0.7908\n","Train Batch [50/219], Loss: 0.1645, Accuracy: 0.7908\n","Train Batch [60/219], Loss: 0.1644, Accuracy: 0.7904\n","Train Batch [70/219], Loss: 0.1640, Accuracy: 0.7878\n","Train Batch [80/219], Loss: 0.1631, Accuracy: 0.7885\n","Train Batch [90/219], Loss: 0.1628, Accuracy: 0.7864\n","Train Batch [100/219], Loss: 0.1623, Accuracy: 0.7862\n","Train Batch [110/219], Loss: 0.1621, Accuracy: 0.7861\n","Train Batch [120/219], Loss: 0.1618, Accuracy: 0.7859\n","Train Batch [130/219], Loss: 0.1614, Accuracy: 0.7859\n","Train Batch [140/219], Loss: 0.1610, Accuracy: 0.7841\n","Train Batch [150/219], Loss: 0.1608, Accuracy: 0.7824\n","Train Batch [160/219], Loss: 0.1604, Accuracy: 0.7838\n","Train Batch [170/219], Loss: 0.1602, Accuracy: 0.7838\n","Train Batch [180/219], Loss: 0.1597, Accuracy: 0.7826\n","Train Batch [190/219], Loss: 0.1593, Accuracy: 0.7826\n","Train Batch [200/219], Loss: 0.1591, Accuracy: 0.7827\n","Train Batch [210/219], Loss: 0.1587, Accuracy: 0.7835\n","Val Batch [0/63], Loss: 0.1579, Accuracy: 0.7458\n","Val Batch [10/63], Loss: 0.1549, Accuracy: 0.7971\n","Val Batch [20/63], Loss: 0.1545, Accuracy: 0.7895\n","Val Batch [30/63], Loss: 0.1539, Accuracy: 0.7872\n","Val Batch [40/63], Loss: 0.1538, Accuracy: 0.7868\n","Val Batch [50/63], Loss: 0.1534, Accuracy: 0.7870\n","Val Batch [60/63], Loss: 0.1531, Accuracy: 0.7881\n","Epoch [8/10], Train Loss: 0.1583, Train Accuracy: 0.7843, Val Loss: 0.1531, Val Accuracy: 0.7887\n","Epoch [9/10]\n","Train Batch [0/219], Loss: 0.1395, Accuracy: 0.8314\n","Train Batch [10/219], Loss: 0.1465, Accuracy: 0.7782\n","Train Batch [20/219], Loss: 0.1481, Accuracy: 0.7748\n","Train Batch [30/219], Loss: 0.1490, Accuracy: 0.7761\n","Train Batch [40/219], Loss: 0.1480, Accuracy: 0.7757\n","Train Batch [50/219], Loss: 0.1481, Accuracy: 0.7799\n","Train Batch [60/219], Loss: 0.1483, Accuracy: 0.7787\n","Train Batch [70/219], Loss: 0.1480, Accuracy: 0.7786\n","Train Batch [80/219], Loss: 0.1476, Accuracy: 0.7802\n","Train Batch [90/219], Loss: 0.1467, Accuracy: 0.7824\n","Train Batch [100/219], Loss: 0.1467, Accuracy: 0.7801\n","Train Batch [110/219], Loss: 0.1465, Accuracy: 0.7795\n","Train Batch [120/219], Loss: 0.1462, Accuracy: 0.7802\n","Train Batch [130/219], Loss: 0.1460, Accuracy: 0.7803\n","Train Batch [140/219], Loss: 0.1457, Accuracy: 0.7793\n","Train Batch [150/219], Loss: 0.1453, Accuracy: 0.7794\n","Train Batch [160/219], Loss: 0.1451, Accuracy: 0.7804\n","Train Batch [170/219], Loss: 0.1447, Accuracy: 0.7806\n","Train Batch [180/219], Loss: 0.1443, Accuracy: 0.7810\n","Train Batch [190/219], Loss: 0.1440, Accuracy: 0.7826\n","Train Batch [200/219], Loss: 0.1435, Accuracy: 0.7838\n","Train Batch [210/219], Loss: 0.1433, Accuracy: 0.7841\n","Val Batch [0/63], Loss: 0.1468, Accuracy: 0.7644\n","Val Batch [10/63], Loss: 0.1435, Accuracy: 0.7721\n","Val Batch [20/63], Loss: 0.1427, Accuracy: 0.7881\n","Val Batch [30/63], Loss: 0.1428, Accuracy: 0.7853\n","Val Batch [40/63], Loss: 0.1416, Accuracy: 0.7874\n","Val Batch [50/63], Loss: 0.1415, Accuracy: 0.7885\n","Val Batch [60/63], Loss: 0.1414, Accuracy: 0.7894\n","Epoch [9/10], Train Loss: 0.1430, Train Accuracy: 0.7842, Val Loss: 0.1412, Val Accuracy: 0.7895\n","Epoch [10/10]\n","Train Batch [0/219], Loss: 0.1378, Accuracy: 0.7485\n","Train Batch [10/219], Loss: 0.1389, Accuracy: 0.7860\n","Train Batch [20/219], Loss: 0.1383, Accuracy: 0.7874\n","Train Batch [30/219], Loss: 0.1381, Accuracy: 0.7912\n","Train Batch [40/219], Loss: 0.1375, Accuracy: 0.7947\n","Train Batch [50/219], Loss: 0.1365, Accuracy: 0.7960\n","Train Batch [60/219], Loss: 0.1361, Accuracy: 0.7926\n","Train Batch [70/219], Loss: 0.1357, Accuracy: 0.7928\n","Train Batch [80/219], Loss: 0.1356, Accuracy: 0.7888\n","Train Batch [90/219], Loss: 0.1354, Accuracy: 0.7900\n","Train Batch [100/219], Loss: 0.1353, Accuracy: 0.7899\n","Train Batch [110/219], Loss: 0.1353, Accuracy: 0.7883\n","Train Batch [120/219], Loss: 0.1350, Accuracy: 0.7879\n","Train Batch [130/219], Loss: 0.1348, Accuracy: 0.7880\n","Train Batch [140/219], Loss: 0.1344, Accuracy: 0.7875\n","Train Batch [150/219], Loss: 0.1340, Accuracy: 0.7875\n","Train Batch [160/219], Loss: 0.1337, Accuracy: 0.7874\n","Train Batch [170/219], Loss: 0.1332, Accuracy: 0.7873\n","Train Batch [180/219], Loss: 0.1328, Accuracy: 0.7877\n","Train Batch [190/219], Loss: 0.1327, Accuracy: 0.7877\n","Train Batch [200/219], Loss: 0.1326, Accuracy: 0.7866\n","Train Batch [210/219], Loss: 0.1323, Accuracy: 0.7869\n","Val Batch [0/63], Loss: 0.1243, Accuracy: 0.8647\n","Val Batch [10/63], Loss: 0.1283, Accuracy: 0.7887\n","Val Batch [20/63], Loss: 0.1289, Accuracy: 0.7816\n","Val Batch [30/63], Loss: 0.1296, Accuracy: 0.7836\n","Val Batch [40/63], Loss: 0.1294, Accuracy: 0.7877\n","Val Batch [50/63], Loss: 0.1295, Accuracy: 0.7866\n","Val Batch [60/63], Loss: 0.1297, Accuracy: 0.7887\n","Epoch [10/10], Train Loss: 0.1322, Train Accuracy: 0.7864, Val Loss: 0.1296, Val Accuracy: 0.7894\n"]},{"output_type":"stream","name":"stderr","text":["Testing:   3%|▎         | 1/32 [00:28<14:56, 28.92s/it]"]},{"output_type":"stream","name":"stdout","text":["Batch 0/32, Current Test Loss: 0.1359, Current Test Accuracy: 0.7697\n"]},{"output_type":"stream","name":"stderr","text":["Testing: 100%|██████████| 32/32 [14:40<00:00, 27.53s/it]"]},{"output_type":"stream","name":"stdout","text":["Test Loss: 0.1295, Test Accuracy: 0.7918\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["train_loader, val_loader, test_loader = create_loaders(train_path=\"/content/drive/Shareddrives/CIS5190FinalProj/Train10000_0.75\",\n","                                                       val_path=\"/content/drive/Shareddrives/CIS5190FinalProj/Val10000_0.75\",\n","                                                       test_path=\"/content/drive/Shareddrives/CIS5190FinalProj/test_dataset\")\n","model, criterion, optimizer = init_vgg19_hyperparameters()\n","\n","## Train the model\n","vgg_train_losses_10000_75, vgg_train_accuracies_10000_75, vgg_val_losses_10000_75, vgg_val_accuracies_10000_75 = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=NUM_EPOCHS)\n","\n","## Test the model\n","vgg_test_loss_10000_75, vgg_test_accuracy_10000_75 = test_model(model, test_loader, criterion)\n","\n","## Save the model\n","torch.save(model.state_dict(), '/content/drive/Shareddrives/CIS5190FinalProj/vgg_10000_75.pth')"]},{"cell_type":"code","source":["save_to_csv(\"/content/drive/Shareddrives/CIS5190FinalProj/results2.csv\",\n","            \"VGG 10000 0.75\",\n","            vgg_train_losses_10000_75,\n","            vgg_train_accuracies_10000_75,\n","            vgg_val_losses_10000_75,\n","            vgg_val_accuracies_10000_75,\n","            vgg_test_loss_10000_75,\n","            vgg_test_accuracy_10000_75)"],"metadata":{"id":"15N28F-SrPm8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5pC97Upo44OO"},"source":["## 10000, 1.0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MwD0-sRc4NeH","colab":{"base_uri":"https://localhost:8080/"},"outputId":"7925fd1b-fa01-40fe-f38a-fdc3bb7bd791"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/10]\n","Train Batch [0/219], Loss: 0.7072, Accuracy: 0.0383\n","Train Batch [10/219], Loss: 0.7023, Accuracy: 0.0383\n","Train Batch [20/219], Loss: 0.6984, Accuracy: 0.0392\n","Train Batch [30/219], Loss: 0.6940, Accuracy: 0.0410\n","Train Batch [40/219], Loss: 0.6892, Accuracy: 0.0432\n","Train Batch [50/219], Loss: 0.6844, Accuracy: 0.0449\n","Train Batch [60/219], Loss: 0.6790, Accuracy: 0.0472\n","Train Batch [70/219], Loss: 0.6739, Accuracy: 0.0495\n","Train Batch [80/219], Loss: 0.6687, Accuracy: 0.0519\n","Train Batch [90/219], Loss: 0.6637, Accuracy: 0.0544\n","Train Batch [100/219], Loss: 0.6589, Accuracy: 0.0570\n","Train Batch [110/219], Loss: 0.6537, Accuracy: 0.0600\n","Train Batch [120/219], Loss: 0.6487, Accuracy: 0.0631\n","Train Batch [130/219], Loss: 0.6439, Accuracy: 0.0664\n","Train Batch [140/219], Loss: 0.6390, Accuracy: 0.0698\n","Train Batch [150/219], Loss: 0.6343, Accuracy: 0.0737\n","Train Batch [160/219], Loss: 0.6295, Accuracy: 0.0779\n","Train Batch [170/219], Loss: 0.6250, Accuracy: 0.0822\n","Train Batch [180/219], Loss: 0.6205, Accuracy: 0.0864\n","Train Batch [190/219], Loss: 0.6161, Accuracy: 0.0910\n","Train Batch [200/219], Loss: 0.6117, Accuracy: 0.0958\n","Train Batch [210/219], Loss: 0.6072, Accuracy: 0.1012\n","Val Batch [0/63], Loss: 0.5048, Accuracy: 0.5787\n","Val Batch [10/63], Loss: 0.5062, Accuracy: 0.5149\n","Val Batch [20/63], Loss: 0.5063, Accuracy: 0.5157\n","Val Batch [30/63], Loss: 0.5063, Accuracy: 0.5195\n","Val Batch [40/63], Loss: 0.5063, Accuracy: 0.5207\n","Val Batch [50/63], Loss: 0.5067, Accuracy: 0.5205\n","Val Batch [60/63], Loss: 0.5068, Accuracy: 0.5210\n","Epoch [1/10], Train Loss: 0.6037, Train Accuracy: 0.1056, Val Loss: 0.5066, Val Accuracy: 0.5209\n","Epoch [2/10]\n","Train Batch [0/219], Loss: 0.5105, Accuracy: 0.2224\n","Train Batch [10/219], Loss: 0.5054, Accuracy: 0.2410\n","Train Batch [20/219], Loss: 0.5022, Accuracy: 0.2516\n","Train Batch [30/219], Loss: 0.4978, Accuracy: 0.2625\n","Train Batch [40/219], Loss: 0.4947, Accuracy: 0.2710\n","Train Batch [50/219], Loss: 0.4913, Accuracy: 0.2801\n","Train Batch [60/219], Loss: 0.4877, Accuracy: 0.2922\n","Train Batch [70/219], Loss: 0.4845, Accuracy: 0.3017\n","Train Batch [80/219], Loss: 0.4813, Accuracy: 0.3127\n","Train Batch [90/219], Loss: 0.4783, Accuracy: 0.3246\n","Train Batch [100/219], Loss: 0.4752, Accuracy: 0.3360\n","Train Batch [110/219], Loss: 0.4724, Accuracy: 0.3463\n","Train Batch [120/219], Loss: 0.4692, Accuracy: 0.3588\n","Train Batch [130/219], Loss: 0.4664, Accuracy: 0.3690\n","Train Batch [140/219], Loss: 0.4635, Accuracy: 0.3804\n","Train Batch [150/219], Loss: 0.4606, Accuracy: 0.3914\n","Train Batch [160/219], Loss: 0.4579, Accuracy: 0.4021\n","Train Batch [170/219], Loss: 0.4550, Accuracy: 0.4142\n","Train Batch [180/219], Loss: 0.4520, Accuracy: 0.4256\n","Train Batch [190/219], Loss: 0.4494, Accuracy: 0.4358\n","Train Batch [200/219], Loss: 0.4468, Accuracy: 0.4462\n","Train Batch [210/219], Loss: 0.4441, Accuracy: 0.4569\n","Val Batch [0/63], Loss: 0.3785, Accuracy: 0.9053\n","Val Batch [10/63], Loss: 0.3854, Accuracy: 0.8716\n","Val Batch [20/63], Loss: 0.3840, Accuracy: 0.8648\n","Val Batch [30/63], Loss: 0.3846, Accuracy: 0.8655\n","Val Batch [40/63], Loss: 0.3846, Accuracy: 0.8653\n","Val Batch [50/63], Loss: 0.3841, Accuracy: 0.8656\n","Val Batch [60/63], Loss: 0.3840, Accuracy: 0.8662\n","Epoch [2/10], Train Loss: 0.4419, Train Accuracy: 0.4649, Val Loss: 0.3839, Val Accuracy: 0.8665\n","Epoch [3/10]\n","Train Batch [0/219], Loss: 0.3770, Accuracy: 0.7150\n","Train Batch [10/219], Loss: 0.3824, Accuracy: 0.7050\n","Train Batch [20/219], Loss: 0.3789, Accuracy: 0.7075\n","Train Batch [30/219], Loss: 0.3774, Accuracy: 0.7180\n","Train Batch [40/219], Loss: 0.3759, Accuracy: 0.7240\n","Train Batch [50/219], Loss: 0.3736, Accuracy: 0.7288\n","Train Batch [60/219], Loss: 0.3717, Accuracy: 0.7331\n","Train Batch [70/219], Loss: 0.3697, Accuracy: 0.7371\n","Train Batch [80/219], Loss: 0.3678, Accuracy: 0.7423\n","Train Batch [90/219], Loss: 0.3659, Accuracy: 0.7475\n","Train Batch [100/219], Loss: 0.3639, Accuracy: 0.7529\n","Train Batch [110/219], Loss: 0.3614, Accuracy: 0.7581\n","Train Batch [120/219], Loss: 0.3594, Accuracy: 0.7636\n","Train Batch [130/219], Loss: 0.3574, Accuracy: 0.7681\n","Train Batch [140/219], Loss: 0.3555, Accuracy: 0.7699\n","Train Batch [150/219], Loss: 0.3536, Accuracy: 0.7732\n","Train Batch [160/219], Loss: 0.3519, Accuracy: 0.7768\n","Train Batch [170/219], Loss: 0.3499, Accuracy: 0.7805\n","Train Batch [180/219], Loss: 0.3480, Accuracy: 0.7837\n","Train Batch [190/219], Loss: 0.3464, Accuracy: 0.7860\n","Train Batch [200/219], Loss: 0.3446, Accuracy: 0.7882\n","Train Batch [210/219], Loss: 0.3429, Accuracy: 0.7904\n","Val Batch [0/63], Loss: 0.3039, Accuracy: 0.8736\n","Val Batch [10/63], Loss: 0.3041, Accuracy: 0.8697\n","Val Batch [20/63], Loss: 0.3070, Accuracy: 0.8668\n","Val Batch [30/63], Loss: 0.3071, Accuracy: 0.8681\n","Val Batch [40/63], Loss: 0.3069, Accuracy: 0.8686\n","Val Batch [50/63], Loss: 0.3063, Accuracy: 0.8724\n","Val Batch [60/63], Loss: 0.3060, Accuracy: 0.8720\n","Epoch [3/10], Train Loss: 0.3415, Train Accuracy: 0.7922, Val Loss: 0.3060, Val Accuracy: 0.8720\n","Epoch [4/10]\n","Train Batch [0/219], Loss: 0.3002, Accuracy: 0.8750\n","Train Batch [10/219], Loss: 0.2995, Accuracy: 0.8569\n","Train Batch [20/219], Loss: 0.3007, Accuracy: 0.8536\n","Train Batch [30/219], Loss: 0.3000, Accuracy: 0.8527\n","Train Batch [40/219], Loss: 0.2986, Accuracy: 0.8493\n","Train Batch [50/219], Loss: 0.2973, Accuracy: 0.8495\n","Train Batch [60/219], Loss: 0.2955, Accuracy: 0.8521\n","Train Batch [70/219], Loss: 0.2942, Accuracy: 0.8529\n","Train Batch [80/219], Loss: 0.2927, Accuracy: 0.8540\n","Train Batch [90/219], Loss: 0.2914, Accuracy: 0.8542\n","Train Batch [100/219], Loss: 0.2901, Accuracy: 0.8536\n","Train Batch [110/219], Loss: 0.2889, Accuracy: 0.8538\n","Train Batch [120/219], Loss: 0.2872, Accuracy: 0.8550\n","Train Batch [130/219], Loss: 0.2859, Accuracy: 0.8551\n","Train Batch [140/219], Loss: 0.2846, Accuracy: 0.8554\n","Train Batch [150/219], Loss: 0.2835, Accuracy: 0.8549\n","Train Batch [160/219], Loss: 0.2823, Accuracy: 0.8551\n","Train Batch [170/219], Loss: 0.2811, Accuracy: 0.8555\n","Train Batch [180/219], Loss: 0.2799, Accuracy: 0.8553\n","Train Batch [190/219], Loss: 0.2786, Accuracy: 0.8554\n","Train Batch [200/219], Loss: 0.2773, Accuracy: 0.8556\n","Train Batch [210/219], Loss: 0.2761, Accuracy: 0.8557\n","Val Batch [0/63], Loss: 0.2571, Accuracy: 0.8765\n","Val Batch [10/63], Loss: 0.2532, Accuracy: 0.8528\n","Val Batch [20/63], Loss: 0.2527, Accuracy: 0.8639\n","Val Batch [30/63], Loss: 0.2530, Accuracy: 0.8669\n","Val Batch [40/63], Loss: 0.2527, Accuracy: 0.8678\n","Val Batch [50/63], Loss: 0.2522, Accuracy: 0.8700\n","Val Batch [60/63], Loss: 0.2519, Accuracy: 0.8719\n","Epoch [4/10], Train Loss: 0.2751, Train Accuracy: 0.8557, Val Loss: 0.2517, Val Accuracy: 0.8723\n","Epoch [5/10]\n","Train Batch [0/219], Loss: 0.2471, Accuracy: 0.8523\n","Train Batch [10/219], Loss: 0.2439, Accuracy: 0.8651\n","Train Batch [20/219], Loss: 0.2459, Accuracy: 0.8680\n","Train Batch [30/219], Loss: 0.2452, Accuracy: 0.8704\n","Train Batch [40/219], Loss: 0.2445, Accuracy: 0.8684\n","Train Batch [50/219], Loss: 0.2442, Accuracy: 0.8674\n","Train Batch [60/219], Loss: 0.2436, Accuracy: 0.8674\n","Train Batch [70/219], Loss: 0.2425, Accuracy: 0.8666\n","Train Batch [80/219], Loss: 0.2416, Accuracy: 0.8655\n","Train Batch [90/219], Loss: 0.2410, Accuracy: 0.8650\n","Train Batch [100/219], Loss: 0.2400, Accuracy: 0.8646\n","Train Batch [110/219], Loss: 0.2394, Accuracy: 0.8651\n","Train Batch [120/219], Loss: 0.2385, Accuracy: 0.8644\n","Train Batch [130/219], Loss: 0.2377, Accuracy: 0.8647\n","Train Batch [140/219], Loss: 0.2368, Accuracy: 0.8653\n","Train Batch [150/219], Loss: 0.2360, Accuracy: 0.8658\n","Train Batch [160/219], Loss: 0.2350, Accuracy: 0.8664\n","Train Batch [170/219], Loss: 0.2341, Accuracy: 0.8663\n","Train Batch [180/219], Loss: 0.2334, Accuracy: 0.8661\n","Train Batch [190/219], Loss: 0.2326, Accuracy: 0.8662\n","Train Batch [200/219], Loss: 0.2319, Accuracy: 0.8661\n","Train Batch [210/219], Loss: 0.2309, Accuracy: 0.8662\n","Val Batch [0/63], Loss: 0.2227, Accuracy: 0.8421\n","Val Batch [10/63], Loss: 0.2143, Accuracy: 0.8697\n","Val Batch [20/63], Loss: 0.2150, Accuracy: 0.8722\n","Val Batch [30/63], Loss: 0.2156, Accuracy: 0.8698\n","Val Batch [40/63], Loss: 0.2151, Accuracy: 0.8697\n","Val Batch [50/63], Loss: 0.2149, Accuracy: 0.8706\n","Val Batch [60/63], Loss: 0.2151, Accuracy: 0.8715\n","Epoch [5/10], Train Loss: 0.2303, Train Accuracy: 0.8663, Val Loss: 0.2150, Val Accuracy: 0.8722\n","Epoch [6/10]\n","Train Batch [0/219], Loss: 0.2196, Accuracy: 0.8324\n","Train Batch [10/219], Loss: 0.2128, Accuracy: 0.8693\n","Train Batch [20/219], Loss: 0.2107, Accuracy: 0.8676\n","Train Batch [30/219], Loss: 0.2102, Accuracy: 0.8634\n","Train Batch [40/219], Loss: 0.2098, Accuracy: 0.8652\n","Train Batch [50/219], Loss: 0.2090, Accuracy: 0.8648\n","Train Batch [60/219], Loss: 0.2080, Accuracy: 0.8623\n","Train Batch [70/219], Loss: 0.2068, Accuracy: 0.8629\n","Train Batch [80/219], Loss: 0.2065, Accuracy: 0.8629\n","Train Batch [90/219], Loss: 0.2053, Accuracy: 0.8643\n","Train Batch [100/219], Loss: 0.2044, Accuracy: 0.8645\n","Train Batch [110/219], Loss: 0.2041, Accuracy: 0.8643\n","Train Batch [120/219], Loss: 0.2033, Accuracy: 0.8654\n","Train Batch [130/219], Loss: 0.2025, Accuracy: 0.8657\n","Train Batch [140/219], Loss: 0.2018, Accuracy: 0.8656\n","Train Batch [150/219], Loss: 0.2011, Accuracy: 0.8661\n","Train Batch [160/219], Loss: 0.2003, Accuracy: 0.8666\n","Train Batch [170/219], Loss: 0.1996, Accuracy: 0.8668\n","Train Batch [180/219], Loss: 0.1990, Accuracy: 0.8668\n","Train Batch [190/219], Loss: 0.1984, Accuracy: 0.8662\n","Train Batch [200/219], Loss: 0.1980, Accuracy: 0.8666\n","Train Batch [210/219], Loss: 0.1976, Accuracy: 0.8662\n","Val Batch [0/63], Loss: 0.1840, Accuracy: 0.8817\n","Val Batch [10/63], Loss: 0.1865, Accuracy: 0.8649\n","Val Batch [20/63], Loss: 0.1875, Accuracy: 0.8653\n","Val Batch [30/63], Loss: 0.1866, Accuracy: 0.8671\n","Val Batch [40/63], Loss: 0.1869, Accuracy: 0.8679\n","Val Batch [50/63], Loss: 0.1866, Accuracy: 0.8708\n","Val Batch [60/63], Loss: 0.1866, Accuracy: 0.8722\n","Epoch [6/10], Train Loss: 0.1970, Train Accuracy: 0.8658, Val Loss: 0.1866, Val Accuracy: 0.8722\n","Epoch [7/10]\n","Train Batch [0/219], Loss: 0.1687, Accuracy: 0.8721\n","Train Batch [10/219], Loss: 0.1796, Accuracy: 0.8689\n","Train Batch [20/219], Loss: 0.1803, Accuracy: 0.8648\n","Train Batch [30/219], Loss: 0.1810, Accuracy: 0.8637\n","Train Batch [40/219], Loss: 0.1807, Accuracy: 0.8672\n","Train Batch [50/219], Loss: 0.1805, Accuracy: 0.8670\n","Train Batch [60/219], Loss: 0.1802, Accuracy: 0.8675\n","Train Batch [70/219], Loss: 0.1796, Accuracy: 0.8672\n","Train Batch [80/219], Loss: 0.1791, Accuracy: 0.8679\n"]}],"source":["train_loader, val_loader, test_loader = create_loaders(train_path=\"/content/drive/Shareddrives/CIS5190FinalProj/Train10000_1.0\",\n","                                                       val_path=\"/content/drive/Shareddrives/CIS5190FinalProj/Val10000_1.0\",\n","                                                       test_path=\"/content/drive/Shareddrives/CIS5190FinalProj/test_dataset\")\n","model, criterion, optimizer = init_vgg19_hyperparameters()\n","\n","## Train the model\n","vgg_train_losses_10000_100, vgg_train_accuracies_10000_100, vgg_val_losses_10000_100, vgg_val_accuracies_10000_100 = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=NUM_EPOCHS)\n","\n","## Test the model\n","vgg_test_loss_10000_100, vgg_test_accuracy_10000_100 = test_model(model, test_loader, criterion)\n","\n","## Save the model\n","torch.save(model.state_dict(), '/content/drive/Shareddrives/CIS5190FinalProj/vgg_10000_100.pth')"]},{"cell_type":"code","source":["save_to_csv(\"/content/drive/Shareddrives/CIS5190FinalProj/results2.csv\",\n","            \"VGG 10000 1.0\",\n","            vgg_train_losses_10000_100,\n","            vgg_train_accuracies_10000_100,\n","            vgg_val_losses_10000_100,\n","            vgg_val_accuracies_10000_100,\n","            vgg_test_loss_10000_100,\n","            vgg_test_accuracy_10000_100)"],"metadata":{"id":"j69mL8Q6rUfO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9U0rPBnl4-GW"},"source":["# ResNet"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IfDRvw4HCfOp"},"outputs":[],"source":["def init_resnet_hyperparameters():\n","    weights = ResNet18_Weights.DEFAULT\n","    resnet = models.resnet18(weights=weights)\n","    for param in resnet.parameters():\n","        param.requires_grad = False\n","\n","    num_features = resnet.fc.in_features\n","    num_elements = 118\n","    resnet.fc = nn.Linear(num_features, num_elements)\n","\n","    resnet = resnet.to(device)\n","\n","    criterion = nn.BCEWithLogitsLoss()\n","    optimizer = torch.optim.SGD(resnet.parameters(), lr=1e-4, momentum=0.9)\n","\n","    return resnet, criterion, optimizer"]},{"cell_type":"markdown","metadata":{"id":"CYEMMvMR6MI0"},"source":["## 5000, 0.25"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sKd7moz0Cp1D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715813014899,"user_tz":-480,"elapsed":640104,"user":{"displayName":"Matthew Kuo","userId":"14965226929628348940"}},"outputId":"922d89c6-59f4-4baa-8580-810e143d9ac8"},"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n","100%|██████████| 44.7M/44.7M [00:01<00:00, 36.5MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/10]\n","Train Batch [0/110], Loss: 0.7331, Accuracy: 0.0377\n","Train Batch [10/110], Loss: 0.7317, Accuracy: 0.0346\n","Train Batch [20/110], Loss: 0.7292, Accuracy: 0.0349\n","Train Batch [30/110], Loss: 0.7256, Accuracy: 0.0353\n","Train Batch [40/110], Loss: 0.7217, Accuracy: 0.0359\n","Train Batch [50/110], Loss: 0.7178, Accuracy: 0.0361\n","Train Batch [60/110], Loss: 0.7139, Accuracy: 0.0365\n","Train Batch [70/110], Loss: 0.7099, Accuracy: 0.0370\n","Train Batch [80/110], Loss: 0.7058, Accuracy: 0.0375\n","Train Batch [90/110], Loss: 0.7017, Accuracy: 0.0381\n","Train Batch [100/110], Loss: 0.6977, Accuracy: 0.0386\n","Val Batch [0/32], Loss: 0.6539, Accuracy: 0.0452\n","Val Batch [10/32], Loss: 0.6506, Accuracy: 0.0433\n","Val Batch [20/32], Loss: 0.6516, Accuracy: 0.0428\n","Val Batch [30/32], Loss: 0.6512, Accuracy: 0.0425\n","Epoch [1/10], Train Loss: 0.6942, Train Accuracy: 0.0390, Val Loss: 0.6514, Val Accuracy: 0.0425\n","Epoch [2/10]\n","Train Batch [0/110], Loss: 0.6513, Accuracy: 0.0433\n","Train Batch [10/110], Loss: 0.6472, Accuracy: 0.0440\n","Train Batch [20/110], Loss: 0.6434, Accuracy: 0.0459\n","Train Batch [30/110], Loss: 0.6397, Accuracy: 0.0464\n","Train Batch [40/110], Loss: 0.6359, Accuracy: 0.0476\n","Train Batch [50/110], Loss: 0.6323, Accuracy: 0.0485\n","Train Batch [60/110], Loss: 0.6287, Accuracy: 0.0491\n","Train Batch [70/110], Loss: 0.6251, Accuracy: 0.0499\n","Train Batch [80/110], Loss: 0.6216, Accuracy: 0.0508\n","Train Batch [90/110], Loss: 0.6182, Accuracy: 0.0514\n","Train Batch [100/110], Loss: 0.6148, Accuracy: 0.0521\n","Val Batch [0/32], Loss: 0.5755, Accuracy: 0.0618\n","Val Batch [10/32], Loss: 0.5771, Accuracy: 0.0607\n","Val Batch [20/32], Loss: 0.5768, Accuracy: 0.0604\n","Val Batch [30/32], Loss: 0.5769, Accuracy: 0.0599\n","Epoch [2/10], Train Loss: 0.6118, Train Accuracy: 0.0527, Val Loss: 0.5770, Val Accuracy: 0.0598\n","Epoch [3/10]\n","Train Batch [0/110], Loss: 0.5765, Accuracy: 0.0563\n","Train Batch [10/110], Loss: 0.5716, Accuracy: 0.0637\n","Train Batch [20/110], Loss: 0.5685, Accuracy: 0.0642\n","Train Batch [30/110], Loss: 0.5655, Accuracy: 0.0652\n","Train Batch [40/110], Loss: 0.5624, Accuracy: 0.0661\n","Train Batch [50/110], Loss: 0.5594, Accuracy: 0.0673\n","Train Batch [60/110], Loss: 0.5566, Accuracy: 0.0680\n","Train Batch [70/110], Loss: 0.5538, Accuracy: 0.0690\n","Train Batch [80/110], Loss: 0.5509, Accuracy: 0.0700\n","Train Batch [90/110], Loss: 0.5480, Accuracy: 0.0717\n","Train Batch [100/110], Loss: 0.5452, Accuracy: 0.0731\n","Val Batch [0/32], Loss: 0.5108, Accuracy: 0.1033\n","Val Batch [10/32], Loss: 0.5132, Accuracy: 0.0873\n","Val Batch [20/32], Loss: 0.5133, Accuracy: 0.0892\n","Val Batch [30/32], Loss: 0.5131, Accuracy: 0.0894\n","Epoch [3/10], Train Loss: 0.5427, Train Accuracy: 0.0744, Val Loss: 0.5134, Val Accuracy: 0.0893\n","Epoch [4/10]\n","Train Batch [0/110], Loss: 0.5137, Accuracy: 0.0961\n","Train Batch [10/110], Loss: 0.5097, Accuracy: 0.0918\n","Train Batch [20/110], Loss: 0.5067, Accuracy: 0.0935\n","Train Batch [30/110], Loss: 0.5042, Accuracy: 0.0970\n","Train Batch [40/110], Loss: 0.5018, Accuracy: 0.0988\n","Train Batch [50/110], Loss: 0.4993, Accuracy: 0.1013\n","Train Batch [60/110], Loss: 0.4969, Accuracy: 0.1037\n","Train Batch [70/110], Loss: 0.4944, Accuracy: 0.1059\n","Train Batch [80/110], Loss: 0.4920, Accuracy: 0.1085\n","Train Batch [90/110], Loss: 0.4896, Accuracy: 0.1105\n","Train Batch [100/110], Loss: 0.4873, Accuracy: 0.1129\n","Val Batch [0/32], Loss: 0.4613, Accuracy: 0.1502\n","Val Batch [10/32], Loss: 0.4596, Accuracy: 0.1408\n","Val Batch [20/32], Loss: 0.4604, Accuracy: 0.1368\n","Val Batch [30/32], Loss: 0.4600, Accuracy: 0.1390\n","Epoch [4/10], Train Loss: 0.4852, Train Accuracy: 0.1153, Val Loss: 0.4601, Val Accuracy: 0.1390\n","Epoch [5/10]\n","Train Batch [0/110], Loss: 0.4615, Accuracy: 0.1399\n","Train Batch [10/110], Loss: 0.4565, Accuracy: 0.1517\n","Train Batch [20/110], Loss: 0.4548, Accuracy: 0.1527\n","Train Batch [30/110], Loss: 0.4528, Accuracy: 0.1551\n","Train Batch [40/110], Loss: 0.4506, Accuracy: 0.1598\n","Train Batch [50/110], Loss: 0.4484, Accuracy: 0.1647\n","Train Batch [60/110], Loss: 0.4464, Accuracy: 0.1679\n","Train Batch [70/110], Loss: 0.4444, Accuracy: 0.1715\n","Train Batch [80/110], Loss: 0.4425, Accuracy: 0.1738\n","Train Batch [90/110], Loss: 0.4405, Accuracy: 0.1773\n","Train Batch [100/110], Loss: 0.4385, Accuracy: 0.1824\n","Val Batch [0/32], Loss: 0.4183, Accuracy: 0.1945\n","Val Batch [10/32], Loss: 0.4182, Accuracy: 0.2170\n","Val Batch [20/32], Loss: 0.4176, Accuracy: 0.2213\n","Val Batch [30/32], Loss: 0.4174, Accuracy: 0.2201\n","Epoch [5/10], Train Loss: 0.4367, Train Accuracy: 0.1858, Val Loss: 0.4178, Val Accuracy: 0.2199\n","Epoch [6/10]\n","Train Batch [0/110], Loss: 0.4152, Accuracy: 0.2471\n","Train Batch [10/110], Loss: 0.4138, Accuracy: 0.2337\n","Train Batch [20/110], Loss: 0.4118, Accuracy: 0.2358\n","Train Batch [30/110], Loss: 0.4098, Accuracy: 0.2418\n","Train Batch [40/110], Loss: 0.4081, Accuracy: 0.2477\n","Train Batch [50/110], Loss: 0.4063, Accuracy: 0.2533\n","Train Batch [60/110], Loss: 0.4045, Accuracy: 0.2588\n","Train Batch [70/110], Loss: 0.4028, Accuracy: 0.2646\n","Train Batch [80/110], Loss: 0.4011, Accuracy: 0.2712\n","Train Batch [90/110], Loss: 0.3994, Accuracy: 0.2777\n","Train Batch [100/110], Loss: 0.3976, Accuracy: 0.2833\n","Val Batch [0/32], Loss: 0.3826, Accuracy: 0.3218\n","Val Batch [10/32], Loss: 0.3801, Accuracy: 0.3309\n","Val Batch [20/32], Loss: 0.3805, Accuracy: 0.3334\n","Val Batch [30/32], Loss: 0.3804, Accuracy: 0.3340\n","Epoch [6/10], Train Loss: 0.3961, Train Accuracy: 0.2884, Val Loss: 0.3813, Val Accuracy: 0.3328\n","Epoch [7/10]\n","Train Batch [0/110], Loss: 0.3781, Accuracy: 0.3614\n","Train Batch [10/110], Loss: 0.3764, Accuracy: 0.3455\n","Train Batch [20/110], Loss: 0.3749, Accuracy: 0.3543\n","Train Batch [30/110], Loss: 0.3736, Accuracy: 0.3561\n","Train Batch [40/110], Loss: 0.3720, Accuracy: 0.3641\n","Train Batch [50/110], Loss: 0.3706, Accuracy: 0.3680\n","Train Batch [60/110], Loss: 0.3691, Accuracy: 0.3767\n","Train Batch [70/110], Loss: 0.3677, Accuracy: 0.3820\n","Train Batch [80/110], Loss: 0.3663, Accuracy: 0.3865\n","Train Batch [90/110], Loss: 0.3646, Accuracy: 0.3941\n","Train Batch [100/110], Loss: 0.3632, Accuracy: 0.3993\n","Val Batch [0/32], Loss: 0.3439, Accuracy: 0.4402\n","Val Batch [10/32], Loss: 0.3498, Accuracy: 0.4440\n","Val Batch [20/32], Loss: 0.3487, Accuracy: 0.4377\n","Val Batch [30/32], Loss: 0.3483, Accuracy: 0.4431\n","Epoch [7/10], Train Loss: 0.3619, Train Accuracy: 0.4045, Val Loss: 0.3483, Val Accuracy: 0.4428\n","Epoch [8/10]\n","Train Batch [0/110], Loss: 0.3440, Accuracy: 0.4821\n","Train Batch [10/110], Loss: 0.3446, Accuracy: 0.4615\n","Train Batch [20/110], Loss: 0.3436, Accuracy: 0.4666\n","Train Batch [30/110], Loss: 0.3426, Accuracy: 0.4719\n","Train Batch [40/110], Loss: 0.3413, Accuracy: 0.4754\n","Train Batch [50/110], Loss: 0.3403, Accuracy: 0.4754\n","Train Batch [60/110], Loss: 0.3390, Accuracy: 0.4818\n","Train Batch [70/110], Loss: 0.3377, Accuracy: 0.4877\n","Train Batch [80/110], Loss: 0.3363, Accuracy: 0.4936\n","Train Batch [90/110], Loss: 0.3352, Accuracy: 0.4955\n","Train Batch [100/110], Loss: 0.3340, Accuracy: 0.4996\n","Val Batch [0/32], Loss: 0.3281, Accuracy: 0.4688\n","Val Batch [10/32], Loss: 0.3199, Accuracy: 0.5318\n","Val Batch [20/32], Loss: 0.3204, Accuracy: 0.5230\n","Val Batch [30/32], Loss: 0.3195, Accuracy: 0.5205\n","Epoch [8/10], Train Loss: 0.3329, Train Accuracy: 0.5022, Val Loss: 0.3193, Val Accuracy: 0.5211\n","Epoch [9/10]\n","Train Batch [0/110], Loss: 0.3198, Accuracy: 0.5543\n","Train Batch [10/110], Loss: 0.3187, Accuracy: 0.5443\n","Train Batch [20/110], Loss: 0.3171, Accuracy: 0.5506\n","Train Batch [30/110], Loss: 0.3160, Accuracy: 0.5540\n","Train Batch [40/110], Loss: 0.3156, Accuracy: 0.5469\n","Train Batch [50/110], Loss: 0.3144, Accuracy: 0.5503\n","Train Batch [60/110], Loss: 0.3134, Accuracy: 0.5522\n","Train Batch [70/110], Loss: 0.3123, Accuracy: 0.5539\n","Train Batch [80/110], Loss: 0.3113, Accuracy: 0.5552\n","Train Batch [90/110], Loss: 0.3102, Accuracy: 0.5573\n","Train Batch [100/110], Loss: 0.3091, Accuracy: 0.5584\n","Val Batch [0/32], Loss: 0.2916, Accuracy: 0.6347\n","Val Batch [10/32], Loss: 0.2980, Accuracy: 0.5691\n","Val Batch [20/32], Loss: 0.2969, Accuracy: 0.5708\n","Val Batch [30/32], Loss: 0.2973, Accuracy: 0.5662\n","Epoch [9/10], Train Loss: 0.3082, Train Accuracy: 0.5605, Val Loss: 0.2977, Val Accuracy: 0.5656\n","Epoch [10/10]\n","Train Batch [0/110], Loss: 0.2971, Accuracy: 0.5325\n","Train Batch [10/110], Loss: 0.2956, Accuracy: 0.5707\n","Train Batch [20/110], Loss: 0.2946, Accuracy: 0.5817\n","Train Batch [30/110], Loss: 0.2938, Accuracy: 0.5815\n","Train Batch [40/110], Loss: 0.2928, Accuracy: 0.5840\n","Train Batch [50/110], Loss: 0.2919, Accuracy: 0.5853\n","Train Batch [60/110], Loss: 0.2911, Accuracy: 0.5887\n","Train Batch [70/110], Loss: 0.2901, Accuracy: 0.5904\n","Train Batch [80/110], Loss: 0.2894, Accuracy: 0.5879\n","Train Batch [90/110], Loss: 0.2885, Accuracy: 0.5888\n","Train Batch [100/110], Loss: 0.2875, Accuracy: 0.5923\n","Val Batch [0/32], Loss: 0.2836, Accuracy: 0.5287\n","Val Batch [10/32], Loss: 0.2767, Accuracy: 0.5836\n","Val Batch [20/32], Loss: 0.2765, Accuracy: 0.5881\n","Val Batch [30/32], Loss: 0.2774, Accuracy: 0.5906\n","Epoch [10/10], Train Loss: 0.2866, Train Accuracy: 0.5928, Val Loss: 0.2776, Val Accuracy: 0.5908\n"]},{"output_type":"stream","name":"stderr","text":["Testing:   6%|▋         | 1/16 [00:00<00:08,  1.80it/s]"]},{"output_type":"stream","name":"stdout","text":["Batch 0/16, Current Test Loss: 0.2774, Current Test Accuracy: 0.6235\n"]},{"output_type":"stream","name":"stderr","text":["Testing: 100%|██████████| 16/16 [00:07<00:00,  2.08it/s]"]},{"output_type":"stream","name":"stdout","text":["Test Loss: 0.2784, Test Accuracy: 0.5507\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["train_loader, val_loader, test_loader = create_loaders(train_path=\"/content/drive/Shareddrives/CIS5190FinalProj/Train5000_0.25\",\n","                                                       val_path=\"/content/drive/Shareddrives/CIS5190FinalProj/Val5000_0.25\",\n","                                                       test_path=\"/content/drive/Shareddrives/CIS5190FinalProj/test_dataset\")\n","model, criterion, optimizer = init_resnet_hyperparameters()\n","\n","## Train the model\n","res_train_losses_5000_25, res_train_accuracies_5000_25, res_val_losses_5000_25, res_val_accuracies_5000_25 = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=NUM_EPOCHS)\n","\n","## Test the model\n","res_test_loss_5000_25, res_test_accuracy_5000_25 = test_model(model, test_loader, criterion)\n","\n","## Save the model\n","torch.save(model.state_dict(), '/content/drive/Shareddrives/CIS5190FinalProj/resnet_5000_25.pth')"]},{"cell_type":"code","source":["save_to_csv(\"/content/drive/Shareddrives/CIS5190FinalProj/results2.csv\",\n","            \"ResNet 5000 0.25\",\n","            res_train_losses_5000_25,\n","            res_train_accuracies_5000_25,\n","            res_val_losses_5000_25,\n","            res_val_accuracies_5000_25,\n","            res_test_loss_5000_25,\n","            res_test_accuracy_5000_25)"],"metadata":{"id":"7PzVam1-Yoj7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"674F6_qb6No0"},"source":["## 5000, 0.5"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lnmfFidDCqR7"},"outputs":[],"source":["train_loader, val_loader, test_loader = create_loaders(train_path=\"/content/drive/Shareddrives/CIS5190FinalProj/Train5000_0.5\",\n","                                                       val_path=\"/content/drive/Shareddrives/CIS5190FinalProj/Val5000_0.5\",\n","                                                       test_path=\"/content/drive/Shareddrives/CIS5190FinalProj/test_dataset\")\n","model, criterion, optimizer = init_resnet_hyperparameters()\n","\n","## Train the model\n","res_train_losses_5000_50, res_train_accuracies_5000_50, res_val_losses_5000_50, res_val_accuracies_5000_50 = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=NUM_EPOCHS)\n","\n","## Test the model\n","res_test_loss_5000_50, res_test_accuracy_5000_50 = test_model(model, test_loader, criterion)\n","\n","## Save the model\n","torch.save(model.state_dict(), '/content/drive/Shareddrives/CIS5190FinalProj/resnet_5000_50.pth')"]},{"cell_type":"code","source":["save_to_csv(\"/content/drive/Shareddrives/CIS5190FinalProj/results2.csv\",\n","            \"ResNet 5000 0.50\",\n","            res_train_losses_5000_50,\n","            res_train_accuracies_5000_50,\n","            res_val_losses_5000_50,\n","            res_val_accuracies_5000_50,\n","            res_test_loss_5000_50,\n","            res_test_accuracy_5000_50)"],"metadata":{"id":"A5eD9A4Sg2NU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G20lkQDa6OwK"},"source":["## 5000, 0.75"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Lmjn0dA8Cqv4"},"outputs":[],"source":["train_loader, val_loader, test_loader = create_loaders(train_path=\"/content/drive/Shareddrives/CIS5190FinalProj/Train5000_0.75\",\n","                                                       val_path=\"/content/drive/Shareddrives/CIS5190FinalProj/Val5000_0.75\",\n","                                                       test_path=\"/content/drive/Shareddrives/CIS5190FinalProj/test_dataset\")\n","model, criterion, optimizer = init_resnet_hyperparameters()\n","\n","## Train the model\n","res_train_losses_5000_75, res_train_accuracies_5000_75, res_val_losses_5000_75, res_val_accuracies_5000_75 = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=NUM_EPOCHS)\n","\n","## Test the model\n","res_test_loss_5000_75, res_test_accuracy_5000_75 = test_model(model, test_loader, criterion)\n","\n","## Save the model\n","torch.save(model.state_dict(), '/content/drive/Shareddrives/CIS5190FinalProj/resnet_5000_75.pth')"]},{"cell_type":"code","source":["save_to_csv(\"/content/drive/Shareddrives/CIS5190FinalProj/results2.csv\",\n","            \"ResNet 5000 0.75\",\n","            res_train_losses_5000_75,\n","            res_train_accuracies_5000_75,\n","            res_val_losses_5000_75,\n","            res_val_accuracies_5000_75,\n","            res_test_loss_5000_75,\n","            res_test_accuracy_5000_75)"],"metadata":{"id":"IgNr8O1yhB4f"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"obGJippc6Q6W"},"source":["## 5000, 1.0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lKY0M_MjCrOX"},"outputs":[],"source":["train_loader, val_loader, test_loader = create_loaders(train_path=\"/content/drive/Shareddrives/CIS5190FinalProj/Train5000_1.0\",\n","                                                       val_path=\"/content/drive/Shareddrives/CIS5190FinalProj/Val5000_1.0\",\n","                                                       test_path=\"/content/drive/Shareddrives/CIS5190FinalProj/test_dataset\")\n","model, criterion, optimizer = init_resnet_hyperparameters()\n","\n","## Train the model\n","res_train_losses_5000_100, res_train_accuracies_5000_100, res_val_losses_5000_100, res_val_accuracies_5000_100 = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=NUM_EPOCHS)\n","\n","## Test the model\n","res_test_loss_5000_100, res_test_accuracy_5000_100 = test_model(model, test_loader, criterion)\n","\n","## Save the model\n","torch.save(model.state_dict(), '/content/drive/Shareddrives/CIS5190FinalProj/resnet_5000_100.pth')"]},{"cell_type":"code","source":["save_to_csv(\"/content/drive/Shareddrives/CIS5190FinalProj/results2.csv\",\n","            \"ResNet 5000 1.00\",\n","            res_train_losses_5000_100,\n","            res_train_accuracies_5000_100,\n","            res_val_losses_5000_100,\n","            res_val_accuracies_5000_100,\n","            res_test_loss_5000_100,\n","            res_test_accuracy_5000_100)"],"metadata":{"id":"ZamvyRCghOb6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FQ1oR9Tl6SE3"},"source":["## 10000, 0.5"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dOF5luN4Crf0"},"outputs":[],"source":["train_loader, val_loader, test_loader = create_loaders(train_path=\"/content/drive/Shareddrives/CIS5190FinalProj/Train10000_0.5\",\n","                                                       val_path=\"/content/drive/Shareddrives/CIS5190FinalProj/Val10000_0.5\",\n","                                                       test_path=\"/content/drive/Shareddrives/CIS5190FinalProj/test_dataset\")\n","model, criterion, optimizer = init_resnet_hyperparameters()\n","\n","## Train the model\n","res_train_losses_10000_50, res_train_accuracies_10000_50, res_val_losses_10000_50, res_val_accuracies_10000_50 = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=NUM_EPOCHS)\n","\n","## Test the model\n","res_test_loss_10000_50, res_test_accuracy_10000_50 = test_model(model, test_loader, criterion)\n","\n","## Save the model\n","torch.save(model.state_dict(), '/content/drive/Shareddrives/CIS5190FinalProj/resnet_10000_50.pth')"]},{"cell_type":"code","source":["save_to_csv(\"/content/drive/Shareddrives/CIS5190FinalProj/results2.csv\",\n","            \"ResNet 10000 0.50\",\n","            res_train_losses_10000_50,\n","            res_train_accuracies_10000_50,\n","            res_val_losses_10000_50,\n","            res_val_accuracies_10000_50,\n","            res_test_loss_10000_50,\n","            res_test_accuracy_10000_50)"],"metadata":{"id":"WravvOWLhX06"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IDZT_4b86T-6"},"source":["## 10000, 0.75"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vq3v8m3sCr3w"},"outputs":[],"source":["train_loader, val_loader, test_loader = create_loaders(train_path=\"/content/drive/Shareddrives/CIS5190FinalProj/Train10000_0.75\",\n","                                                       val_path=\"/content/drive/Shareddrives/CIS5190FinalProj/Val10000_0.75\",\n","                                                       test_path=\"/content/drive/Shareddrives/CIS5190FinalProj/test_dataset\")\n","model, criterion, optimizer = init_resnet_hyperparameters()\n","\n","## Train the model\n","res_train_losses_10000_75, res_train_accuracies_10000_75, res_val_losses_10000_75, res_val_accuracies_10000_75 = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=NUM_EPOCHS)\n","\n","## Test the model\n","res_test_loss_10000_75, res_test_accuracy_10000_75 = test_model(model, test_loader, criterion)\n","\n","## Save the model\n","torch.save(model.state_dict(), '/content/drive/Shareddrives/CIS5190FinalProj/resnet_10000_75.pth')"]},{"cell_type":"code","source":["save_to_csv(\"/content/drive/Shareddrives/CIS5190FinalProj/results2.csv\",\n","            \"ResNet 10000 0.75\",\n","            res_train_losses_10000_75,\n","            res_train_accuracies_10000_75,\n","            res_val_losses_10000_75,\n","            res_val_accuracies_10000_75,\n","            res_test_loss_10000_75,\n","            res_test_accuracy_10000_75)"],"metadata":{"id":"Wp1dGp43hhvI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j1nXJowU6WB-"},"source":["## 10000, 1.0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PCPkfFHn6NUa"},"outputs":[],"source":["train_loader, val_loader, test_loader = create_loaders(train_path=\"/content/drive/Shareddrives/CIS5190FinalProj/Train10000_1.0\",\n","                                                       val_path=\"/content/drive/Shareddrives/CIS5190FinalProj/Val10000_1.0\",\n","                                                       test_path=\"/content/drive/Shareddrives/CIS5190FinalProj/test_dataset\")\n","model, criterion, optimizer = init_resnet_hyperparameters()\n","\n","## Train the model\n","res_train_losses_10000_100, res_train_accuracies_10000_100, res_val_losses_10000_100, res_val_accuracies_10000_100 = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=NUM_EPOCHS)\n","\n","## Test the model\n","res_test_loss_10000_100, res_test_accuracy_10000_100 = test_model(model, test_loader, criterion)\n","\n","## Save the model\n","torch.save(model.state_dict(), '/content/drive/Shareddrives/CIS5190FinalProj/resnet_10000_100.pth')"]},{"cell_type":"code","source":["save_to_csv(\"/content/drive/Shareddrives/CIS5190FinalProj/results2.csv\",\n","            \"ResNet 10000 1.00\",\n","            res_train_losses_10000_100,\n","            res_train_accuracies_10000_100,\n","            res_val_losses_10000_100,\n","            res_val_accuracies_10000_100,\n","            res_test_loss_10000_100,\n","            res_test_accuracy_10000_100)"],"metadata":{"id":"x0ieruI9hsJU"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","toc_visible":true,"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}